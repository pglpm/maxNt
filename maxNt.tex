%% Author: PGL  Porta Mana
%% Created: 2015-11-04T09:20:08+0100
%% Last-Updated: 2017-05-18T14:02:33+0200
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Report-no: ***
\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2017
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2017}

\usepackage[final,nonatbib]{nips_2017}
\newcommand*{\firstdraft}{4 November 2015}
\newcommand*{\pdftitle}{Representative random samples\\ and maximum-entropy
  distributions:\\ a dilemma}
\newcommand*{\headtitle}{\pdftitle}
\newcommand*{\pdfauthor}{P.G.L.  Porta Mana, V. Rostami, E. Torre}

\usepackage{newtxmath}
%\usepackage{pifont}
%\usepackage{fontawesome}
\usepackage[T1]{fontenc} 
\input{glyphtounicode} \pdfgentounicode=1
\usepackage[utf8]{inputenx}
%\usepackage{newunicodechar}
% \newunicodechar{Ĕ}{\u{E}}
% \newunicodechar{ĕ}{\u{e}}
% \newunicodechar{Ĭ}{\u{I}}
% \newunicodechar{ĭ}{\u{\i}}
% \newunicodechar{Ŏ}{\u{O}}
% \newunicodechar{ŏ}{\u{o}}
% \newunicodechar{Ŭ}{\u{U}}
% \newunicodechar{ŭ}{\u{u}}
% \newunicodechar{Ā}{\=A}
% \newunicodechar{ā}{\=a}
% \newunicodechar{Ē}{\=E}
% \newunicodechar{ē}{\=e}
% \newunicodechar{Ī}{\=I}
% \newunicodechar{ī}{\={\i}}
% \newunicodechar{Ō}{\=O}
% \newunicodechar{ō}{\=o}
% \newunicodechar{Ū}{\=U}
% \newunicodechar{ū}{\=u}
% \newunicodechar{Ȳ}{\=Y}
% \newunicodechar{ȳ}{\=y}

\newcommand*{\bmmax}{3} % reduce number of bold fonts, before bm
\newcommand*{\hmmax}{0} % reduce number of heavy fonts, before bm
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{mathtools}
\setlength{\multlinegap}{0pt}

\usepackage{amssymb}
\usepackage{amsxtra}

\usepackage[british]{babel}\selectlanguage{british}
\newcommand*{\langfrench}{\foreignlanguage{french}}
\newcommand*{\langgerman}{\foreignlanguage{german}}
\newcommand*{\langitalian}{\foreignlanguage{italian}}
\newcommand*{\langswedish}{\foreignlanguage{swedish}}
\newcommand*{\langlatin}{\foreignlanguage{latin}}
\newcommand*{\langnohyph}{\foreignlanguage{nohyphenation}}

\usepackage[autostyle=false,autopunct=false,english=british]{csquotes}
\setquotestyle{american}

\let\openbox\relax
\usepackage{amsthm}
\newcommand*{\QED}{\textsc{q.e.d.}}
\renewcommand*{\qedsymbol}{\QED}
\theoremstyle{remark}
\newtheorem{note}{Note}
\newtheorem*{remark}{Note}
\newtheoremstyle{innote}{\parsep}{\parsep}{\footnotesize}{}{}{}{0pt}{}
\theoremstyle{innote}
\newtheorem*{innote}{}

\usepackage{bm}

\iffalse
\usepackage[shortlabels,inline]{enumitem}
\SetEnumitemKey{para}{itemindent=\parindent,leftmargin=0pt,listparindent=\parindent,parsep=0pt,itemsep=\topsep}
% \begin{asparaenum} = \begin{enumerate}[para]
% \begin{inparaenum} = \begin{enumerate*}
\setlist[enumerate,2]{label=\alph*.}
\setlist[enumerate]{leftmargin=\parindent}
\setlist[itemize]{leftmargin=\parindent}
\setlist[description]{leftmargin=\parindent}
\fi

%% With euler font cursive for Greek letters - the [1] means 100% scaling
\DeclareFontFamily{U}{egreek}{\skewchar\font'177}%
\DeclareFontShape{U}{egreek}{m}{n}{<-6>s*[0.95]eurm5 <6-8>s*[0.95]eurm7 <8->s*[0.95]eurm10}{}%
\DeclareFontShape{U}{egreek}{m}{it}{<->s*[0.95]eurmo10}{}%
\DeclareFontShape{U}{egreek}{b}{n}{<-6>s*[0.95]eurb5 <6-8>s*[0.95]eurb7 <8->s*[0.95]eurb10}{}%
\DeclareFontShape{U}{egreek}{b}{it}{<->s*[0.95]eurbo10}{}%
\DeclareSymbolFont{egreeki}{U}{egreek}{m}{it}%
\SetSymbolFont{egreeki}{bold}{U}{egreek}{b}{it}% from the amsfonts package
\DeclareSymbolFont{egreekr}{U}{egreek}{m}{n}%
\SetSymbolFont{egreekr}{bold}{U}{egreek}{b}{n}% from the amsfonts package
% Take also \sum, \prod, \coprod symbols from Euler fonts
\DeclareFontFamily{U}{egreekx}{\skewchar\font'177}
\DeclareFontShape{U}{egreekx}{m}{n}{%
       <-7.5>s*[0.9]euex7%
    <7.5-8.5>s*[0.9]euex8%
    <8.5-9.5>s*[0.9]euex9%
    <9.5->s*[0.9]euex10%
}{}
\DeclareSymbolFont{egreekx}{U}{egreekx}{m}{n}
\DeclareMathSymbol{\sumop}{\mathop}{egreekx}{"50}
\DeclareMathSymbol{\prodop}{\mathop}{egreekx}{"51}
\DeclareMathSymbol{\coprodop}{\mathop}{egreekx}{"60}
\makeatletter
\def\sum{\DOTSI\sumop\slimits@}
\def\prod{\DOTSI\prodop\slimits@}
\def\coprod{\DOTSI\coprodop\slimits@}
\makeatother
% Greek letters not usually given in LaTeX. Comment the unneeded ones
% \DeclareMathSymbol{\varpartial}{\mathalpha}{egreeki}{"40}
% \DeclareMathSymbol{\partialup}{\mathalpha}{egreekr}{"40}
% \DeclareMathSymbol{\alpha}{\mathalpha}{egreeki}{"0B}
% \DeclareMathSymbol{\beta}{\mathalpha}{egreeki}{"0C}
% \DeclareMathSymbol{\gamma}{\mathalpha}{egreeki}{"0D}
% \DeclareMathSymbol{\delta}{\mathalpha}{egreeki}{"0E}
% \DeclareMathSymbol{\epsilon}{\mathalpha}{egreeki}{"0F}
% \DeclareMathSymbol{\zeta}{\mathalpha}{egreeki}{"10}
% \DeclareMathSymbol{\eta}{\mathalpha}{egreeki}{"11}
% \DeclareMathSymbol{\theta}{\mathalpha}{egreeki}{"12}
% \DeclareMathSymbol{\iota}{\mathalpha}{egreeki}{"13}
% \DeclareMathSymbol{\kappa}{\mathalpha}{egreeki}{"14}
% \DeclareMathSymbol{\lambda}{\mathalpha}{egreeki}{"15}
% \DeclareMathSymbol{\mu}{\mathalpha}{egreeki}{"16}
% \DeclareMathSymbol{\nu}{\mathalpha}{egreeki}{"17}
% \DeclareMathSymbol{\xi}{\mathalpha}{egreeki}{"18}
% \DeclareMathSymbol{\omicron}{\mathalpha}{egreeki}{"6F}
% \DeclareMathSymbol{\pi}{\mathalpha}{egreeki}{"19}
% \DeclareMathSymbol{\rho}{\mathalpha}{egreeki}{"1A}
% \DeclareMathSymbol{\sigma}{\mathalpha}{egreeki}{"1B}
% \DeclareMathSymbol{\tau}{\mathalpha}{egreeki}{"1C}
% \DeclareMathSymbol{\upsilon}{\mathalpha}{egreeki}{"1D}
% \DeclareMathSymbol{\phi}{\mathalpha}{egreeki}{"1E}
% \DeclareMathSymbol{\chi}{\mathalpha}{egreeki}{"1F}
% \DeclareMathSymbol{\psi}{\mathalpha}{egreeki}{"20}
% \DeclareMathSymbol{\omega}{\mathalpha}{egreeki}{"21}
% \DeclareMathSymbol{\varepsilon}{\mathalpha}{egreeki}{"22}
% \DeclareMathSymbol{\vartheta}{\mathalpha}{egreeki}{"23}
% \DeclareMathSymbol{\varpi}{\mathalpha}{egreeki}{"24}
% \let\varrho\rho 
% \let\varsigma\sigma
% \let\varkappa\kappa
% \DeclareMathSymbol{\varphi}{\mathalpha}{egreeki}{"27}
% %
% \DeclareMathSymbol{\varAlpha}{\mathalpha}{egreeki}{"41}
% \DeclareMathSymbol{\varBeta}{\mathalpha}{egreeki}{"42}
% \DeclareMathSymbol{\varGamma}{\mathalpha}{egreeki}{"00}
% \DeclareMathSymbol{\varDelta}{\mathalpha}{egreeki}{"01}
% \DeclareMathSymbol{\varEpsilon}{\mathalpha}{egreeki}{"45}
% \DeclareMathSymbol{\varZeta}{\mathalpha}{egreeki}{"5A}
% \DeclareMathSymbol{\varEta}{\mathalpha}{egreeki}{"48}
% \DeclareMathSymbol{\varTheta}{\mathalpha}{egreeki}{"02}
 \DeclareMathSymbol{\varIota}{\mathalpha}{egreeki}{"49}
 \DeclareMathSymbol{\varKappa}{\mathalpha}{egreeki}{"4B}
% \DeclareMathSymbol{\varLambda}{\mathalpha}{egreeki}{"03}
% \DeclareMathSymbol{\varMu}{\mathalpha}{egreeki}{"4D}
% \DeclareMathSymbol{\varNu}{\mathalpha}{egreeki}{"4E}
% \DeclareMathSymbol{\varXi}{\mathalpha}{egreeki}{"04}
% \DeclareMathSymbol{\varOmicron}{\mathalpha}{egreeki}{"4F}
% \DeclareMathSymbol{\varPi}{\mathalpha}{egreeki}{"05}
% \DeclareMathSymbol{\varRho}{\mathalpha}{egreeki}{"50}
% \DeclareMathSymbol{\varSigma}{\mathalpha}{egreeki}{"06}
% \DeclareMathSymbol{\varTau}{\mathalpha}{egreeki}{"54}
 \DeclareMathSymbol{\varUpsilon}{\mathalpha}{egreeki}{"07}
% \DeclareMathSymbol{\varPhi}{\mathalpha}{egreeki}{"08}
% \DeclareMathSymbol{\varChi}{\mathalpha}{egreeki}{"58}
% \DeclareMathSymbol{\varPsi}{\mathalpha}{egreeki}{"09}
% \DeclareMathSymbol{\varOmega}{\mathalpha}{egreeki}{"0A} 
% %
% \DeclareMathSymbol{\Alpha}{\mathalpha}{egreekr}{"41}
% \DeclareMathSymbol{\Beta}{\mathalpha}{egreekr}{"42}
% \DeclareMathSymbol{\Gamma}{\mathalpha}{egreekr}{"00}
% \DeclareMathSymbol{\Delta}{\mathalpha}{egreekr}{"01}
% \DeclareMathSymbol{\Epsilon}{\mathalpha}{egreekr}{"45}
% \DeclareMathSymbol{\Zeta}{\mathalpha}{egreekr}{"5A}
% \DeclareMathSymbol{\Eta}{\mathalpha}{egreekr}{"48}
% \DeclareMathSymbol{\Theta}{\mathalpha}{egreekr}{"02}
% \DeclareMathSymbol{\Iota}{\mathalpha}{egreekr}{"49}
% \DeclareMathSymbol{\Kappa}{\mathalpha}{egreekr}{"4B}
% \DeclareMathSymbol{\Lambda}{\mathalpha}{egreekr}{"03}
% \DeclareMathSymbol{\Mu}{\mathalpha}{egreekr}{"4D}
% \DeclareMathSymbol{\Nu}{\mathalpha}{egreekr}{"4E}
% \DeclareMathSymbol{\Xi}{\mathalpha}{egreekr}{"04}
% \DeclareMathSymbol{\Omicron}{\mathalpha}{egreekr}{"4F}
% \DeclareMathSymbol{\Pi}{\mathalpha}{egreekr}{"05}
% \DeclareMathSymbol{\Rho}{\mathalpha}{egreekr}{"50}
% \DeclareMathSymbol{\Sigma}{\mathalpha}{egreekr}{"06}
% \DeclareMathSymbol{\Tau}{\mathalpha}{egreekr}{"54}
% \DeclareMathSymbol{\Upsilon}{\mathalpha}{egreekr}{"07}
% \DeclareMathSymbol{\Phi}{\mathalpha}{egreekr}{"08}
% \DeclareMathSymbol{\Chi}{\mathalpha}{egreekr}{"58}
% \DeclareMathSymbol{\Psi}{\mathalpha}{egreekr}{"09}
% \DeclareMathSymbol{\Omega}{\mathalpha}{egreekr}{"0A}
% %
% \DeclareMathSymbol{\alphaup}{\mathalpha}{egreekr}{"0B}
% \DeclareMathSymbol{\betaup}{\mathalpha}{egreekr}{"0C}
% \DeclareMathSymbol{\gammaup}{\mathalpha}{egreekr}{"0D}
% \DeclareMathSymbol{\deltaup}{\mathalpha}{egreekr}{"0E}
% \DeclareMathSymbol{\epsilonup}{\mathalpha}{egreekr}{"0F}
% \DeclareMathSymbol{\zetaup}{\mathalpha}{egreekr}{"10}
% \DeclareMathSymbol{\etaup}{\mathalpha}{egreekr}{"11}
% \DeclareMathSymbol{\thetaup}{\mathalpha}{egreekr}{"12}
% \DeclareMathSymbol{\iotaup}{\mathalpha}{egreekr}{"13}
% \DeclareMathSymbol{\kappaup}{\mathalpha}{egreekr}{"14}
% \DeclareMathSymbol{\lambdaup}{\mathalpha}{egreekr}{"15}
% \DeclareMathSymbol{\muup}{\mathalpha}{egreekr}{"16}
% \DeclareMathSymbol{\nuup}{\mathalpha}{egreekr}{"17}
% \DeclareMathSymbol{\xiup}{\mathalpha}{egreekr}{"18}
% \DeclareMathSymbol{\omicronup}{\mathalpha}{egreekr}{"6F}
%  \DeclareMathSymbol{\piup}{\mathalpha}{egreekr}{"19}
% \DeclareMathSymbol{\rhoup}{\mathalpha}{egreekr}{"1A}
% \DeclareMathSymbol{\sigmaup}{\mathalpha}{egreekr}{"1B}
% \DeclareMathSymbol{\tauup}{\mathalpha}{egreekr}{"1C}
% \DeclareMathSymbol{\upsilonup}{\mathalpha}{egreekr}{"1D}
% \DeclareMathSymbol{\phiup}{\mathalpha}{egreekr}{"1E}
% \DeclareMathSymbol{\chiup}{\mathalpha}{egreekr}{"1F}
% \DeclareMathSymbol{\psiup}{\mathalpha}{egreekr}{"20}
% \DeclareMathSymbol{\omegaup}{\mathalpha}{egreekr}{"21}
% \DeclareMathSymbol{\varepsilonup}{\mathalpha}{egreekr}{"22}
% \DeclareMathSymbol{\varthetaup}{\mathalpha}{egreekr}{"23}
% \DeclareMathSymbol{\varpiup}{\mathalpha}{egreekr}{"24}
% \let\varrhoup\rhoup 
% \let\varsigmaup\sigmaup
% \let\varkappaup\kappaup
% \DeclareMathSymbol{\varphiup}{\mathalpha}{egreekr}{"27}

%\newcommand*{\mathte}[1]{\textbf{\textit{\textsf{#1}}}}
% Upright sans-serif math alphabet
% \DeclareMathAlphabet{\mathsu}  {T1}{\sfdefault}{m}{n}
% \SetMathAlphabet{\mathsu}{bold}{T1}{\sfdefault}{b}{n}

\usepackage{mathdots}

\usepackage[usenames]{xcolor}
\definecolor{myblue}{RGB}{51,34,136}
\definecolor{mygreen}{RGB}{17,119,51}
\definecolor{myred}{RGB}{136,34,85}
\definecolor{myyellow}{RGB}{153,153,51}
\definecolor{mylightyellow}{RGB}{221,204,119}


\usepackage{microtype}

\usepackage[backend=biber,mcite,subentry,citestyle=numeric-comp,bibstyle=numericbringhurst,autopunct=false,sorting=none,sortcites=false,natbib=false,maxnames=8,minnames=8,giveninits=true,block=space,hyperref=true,defernumbers=false,useprefix=true,language=british]{biblatex}
\renewcommand*{\finalnamedelim}{, }
\setcounter{biburlnumpenalty}{1}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{1}
\DeclareDelimFormat{multicitedelim}{\addsemicolon\space}
\DeclareDelimFormat{postnotedelim}{\space}
\addbibresource{portamanabib.bib}
\renewcommand{\bibfont}{\footnotesize}
%\defbibheading{bibliography}[\bibname]{\section*{#1}\addcontentsline{toc}{section}{#1}%\markboth{#1}{#1}
%}
\newcommand*{\citep}{\parencites}
\newcommand*{\citey}{\parencites*}
\renewcommand*{\cite}{\citep}
\providecommand{\href}[2]{#2}
\providecommand{\eprint}[2]{\texttt{\href{#1}{#2}}}
\newcommand*{\amp}{\&}

\def\arxivp{}
\def\mparcp{}
\def\philscip{}
\def\biorxivp{}
\newcommand*{\arxivsi}{\texttt{arXiv} eprints available at \url{http://arxiv.org/}.\\}
\newcommand*{\mparcsi}{\texttt{mp\_arc} eprints available at \url{http://www.ma.utexas.edu/mp_arc/}.\\}
\newcommand*{\philscisi}{\texttt{philsci} eprints available at \url{http://philsci-archive.pitt.edu/}.\\}
\newcommand*{\biorxivsi}{\texttt{bioRxiv} eprints available at \url{http://biorxiv.org/}.\\}
\newcommand*{\arxiveprint}[1]{\global\def\arxivp{\arxivsi}%\citeauthor{0arxivcite}\addtocategory{ifarchcit}{0arxivcite}%eprint
\texttt{\urlalt{http://arxiv.org/abs/#1}{arXiv:\hspace{0pt}#1}}%
%\texttt{\href{http://arxiv.org/abs/#1}{\protect\url{arXiv:#1}}}%
%\renewcommand{\arxivnote}{\texttt{arXiv} eprints available at \url{http://arxiv.org/}.}
}
\newcommand*{\mparceprint}[1]{\global\def\mparcp{\mparcsi}%\citeauthor{0mparccite}\addtocategory{ifarchcit}{0mparccite}%eprint
\texttt{\urlalt{http://www.ma.utexas.edu/mp_arc-bin/mpa?yn=#1}{mp\_arc:\hspace{0pt}#1}}%
%\texttt{\href{http://www.ma.utexas.edu/mp_arc-bin/mpa?yn=#1}{\protect\url{mp_arc:#1}}}%
%\providecommand{\mparcnote}{\texttt{mp_arc} eprints available at \url{http://www.ma.utexas.edu/mp_arc/}.}
}
\newcommand*{\philscieprint}[1]{\global\def\philscip{\philscisi}%\citeauthor{0philscicite}\addtocategory{ifarchcit}{0philscicite}%eprint
\texttt{\urlalt{http://philsci-archive.pitt.edu/archive/#1}{PhilSci:\hspace{0pt}#1}}%
%\texttt{\href{http://philsci-archive.pitt.edu/archive/#1}{\protect\url{PhilSci:#1}}}%
%\providecommand{\mparcnote}{\texttt{philsci} eprints available at \url{http://philsci-archive.pitt.edu/}.}
}
\newcommand*{\biorxiveprint}[1]{\global\def\biorxivp{\biorxivsi}%\citeauthor{0arxivcite}\addtocategory{ifarchcit}{0arxivcite}%eprint
\texttt{\urlalt{http://biorxiv.org/content/early/#1}{bioRxiv:\hspace{0pt}#1}}%
%\texttt{\href{http://arxiv.org/abs/#1}{\protect\url{arXiv:#1}}}%
%\renewcommand{\arxivnote}{\texttt{arXiv} eprints available at \url{http://arxiv.org/}.}
}

\usepackage{graphicx}

\usepackage{hyperref}
\usepackage[depth=4]{bookmark}
\hypersetup{colorlinks=true,bookmarksnumbered,pdfborder={0 0 0.25},citebordercolor={0.2 0.1333 0.5333},%bluish
citecolor=myblue,linkbordercolor={0.0667 0.4667 0.2},%greenish
linkcolor=myred,urlbordercolor={0.5333 0.1333 0.3333},%reddish
urlcolor=mygreen,breaklinks=true,pdftitle={\pdftitle},pdfauthor={\pdfauthor}}

% \usepackage[vertfit=local]{breakurl}% only for arXiv
\providecommand*{\urlalt}{\href}

\usepackage{wrapfig}
\usepackage{datetime2}
\DTMnewdatestyle{mydate}%
{% definitions
\renewcommand*{\DTMdisplaydate}[4]{%
\number##3\ \DTMenglishmonthname{##2} ##1}%
\renewcommand*{\DTMDisplaydate}{\DTMdisplaydate}%
}
\DTMsetdatestyle{mydate}


% handling orphan/widow lines:
\clubpenalty=10000
\widowpenalty=10000
\raggedbottom

\selectlanguage{british}\frenchspacing

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2017}

%\usepackage[utf8]{inputenc} % allow utf-8 input
%\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
%\usepackage{hyperref}       % hyperlinks
%\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
%\usepackage{amsfonts}       % blackboard math symbols
%\usepackage{nicefrac}       % compact symbols for 1/2, etc.
%\usepackage{microtype}      % microtypography

% @@@@@@@@@@ new macros @@@@@@@@@@
% Common ones - uncomment as needed
%\providecommand{\nequiv}{\not\equiv}
%\providecommand{\coloneqq}{\mathrel{\mathop:}=}
%\providecommand{\eqqcolon}{=\mathrel{\mathop:}}
%\providecommand{\varprod}{\prod}
%\newcommand*{\de}{\partialup}%partial diff
%\newcommand*{\pu}{\piup}%constant pi
\newcommand*{\delt}{\deltaup}%Kronecker, Dirac
%\newcommand*{\eps}{\varepsilonup}%Levi-Civita, Heaviside
%\newcommand*{\riem}{\zetaup}%Riemann zeta
%\providecommand{\degree}{\textdegree}% degree
%\newcommand*{\celsius}{\textcelsius}% degree Celsius
%\newcommand*{\micro}{\textmu}% degree Celsius
%\newcommand*{\I}{\mathrm{i}}%imaginary unit
%\newcommand*{\e}{\mathrm{e}}%Neper
%\newcommand*{\di}{\mathrm{d}}%differential
%\newcommand*{\Di}{\mathrm{D}}%capital differential
%\newcommand*{\planckc}{\hslash}
%\newcommand*{\avogn}{N_{\textrm{A}}}
%\newcommand*{\NN}{\bm{\mathrm{N}}}
%\newcommand*{\ZZ}{\bm{\mathrm{Z}}}
%\newcommand*{\QQ}{\bm{\mathrm{Q}}}
\newcommand*{\RR}{\bm{\mathrm{R}}}
%\newcommand*{\CC}{\bm{\mathrm{C}}}
%\newcommand*{\nabl}{\bm{\nabla}}%nabla
%\DeclareMathOperator{\lb}{lb}%base 2 log
%\DeclareMathOperator{\tr}{tr}%trace
%\DeclareMathOperator{\card}{card}%cardinality
%\DeclareMathOperator{\im}{Im}%im part
%\DeclareMathOperator{\re}{Re}%re part
%\DeclareMathOperator{\sgn}{sgn}%signum
%\DeclareMathOperator{\ent}{ent}%integer less or equal to
%\DeclareMathOperator{\Ord}{O}%same order as
%\DeclareMathOperator{\ord}{o}%lower order than
%\newcommand*{\incr}{\triangle}%finite increment
\newcommand*{\defd}{\coloneqq}
\newcommand*{\defs}{\eqqcolon}
%\newcommand*{\Land}{\bigwedge}
%\newcommand*{\Lor}{\bigvee}
%\newcommand*{\lland}{\mathbin{\ \land\ }}
%\newcommand*{\llor}{\mathbin{\ \lor\ }}
%\newcommand*{\lonlyif}{\mathbin{\Rightarrow}}%implies
\newcommand*{\limplies}{\mathbin{\Rightarrow}}%implies
%\newcommand*{\mimplies}{\Rightarrow}%implies
%\newcommand*{\liff}{\mathbin{\Leftrightarrow}}%if and only if
\renewcommand*{\|}{\mathpunct{|}}%conditional sign (in probabilities)
%\newcommand*{\lcond}{\mathpunct{|\ }}%conditional sign (in probabilities)
%\newcommand*{\bigcond}{\mathpunct{\big|}}%conditional sign (in probabilities)
%\newcommand*{\lbigcond}{\mathpunct{\big|\ }}%conditional sign (in probabilities)
%\newcommand*{\suchthat}{\mid}%{\mathpunct{|}}%such that (eg in sets)
%\newcommand*{\bigst}{\mathpunct{\big|}}%such that (eg in sets)
%\newcommand*{\with}{\colon}%with (list of indices)
%\newcommand*{\mul}{\times}%multiplication
%\newcommand*{\inn}{\cdot}%inner product
\newcommand*{\dotv}{\mathord{\,\cdot\,}}%variable place
%\newcommand*{\comp}{\circ}%composition of functions
%\newcommand*{\con}{\mathbin{:}}%scal prod of tensors
%\newcommand*{\equi}{\sim}%equivalent to 
%\newcommand*{\corr}{\mathrel{\hat{=}}}%corresponds to
%\providecommand{\varparallel}{\ensuremath{\mathbin{/\mkern-7mu/}}}%parallel (tentative symbol)
\renewcommand{\le}{\leqslant}%less or equal
\renewcommand{\ge}{\geqslant}%greater or equal
\DeclarePairedDelimiter\clcl{[}{]}
%\DeclarePairedDelimiter\clop{[}{[}
%\DeclarePairedDelimiter\opcl{]}{]}
%\DeclarePairedDelimiter\opop{]}{[}
%\DeclarePairedDelimiter\abs{\lvert}{\rvert}
%\DeclarePairedDelimiter\norm{\lVert}{\rVert}
\DeclarePairedDelimiter\set{\{}{\}}
%\DeclareMathOperator{\pr}{P}%probability
\newcommand*{\pf}{\mathrm{p}}%probability
\newcommand*{\p}{\mathrm{P}}%probability
%\newcommand*{\tf}{\mathrm{T}}%probability
%\renewcommand*{\|}{\|}
%\newcommand*{\+}{\lor}
%\renewcommand{\*}{\land}
\newcommand*{\sect}{\S}% Sect.~
\newcommand*{\sects}{\S\S}% Sect.~
\newcommand*{\chap}{ch.}%
\newcommand*{\chaps}{chs}%
%\newcommand*{\fn}{fn}%
\newcommand*{\eqn}{eq.}%
\newcommand*{\eqns}{eqs}%
\newcommand*{\fig}{fig.}%
\newcommand*{\figs}{figs}%
%\newcommand*{\vs}{{vs.}}
%\newcommand*{\etc}{{etc.}}
\newcommand*{\ie}{{i.e.}}
%\newcommand*{\ca}{{c.}}
%\newcommand*{\Ie}{{I.e.}}
%\newcommand*{\Eg}{{E.g.}}
\newcommand*{\eg}{{e.g.}}
%\newcommand*{\viz}{{viz}}
\newcommand*{\cf}{{cf.}}
%\newcommand*{\Cf}{{Cf.}}
%\newcommand*{\vd}{{v.}}
%\newcommand*{\Vd}{{V.}}
%\newcommand*{\etal}{{et al.}}
%\newcommand*{\etsim}{{et sim.}}
%\newcommand*{\ibid}{{ibid.}}
%\newcommand*{\sic}{{sic}}
%\newcommand*{\id}{\mathte{I}}%id matrix
%\newcommand*{\nbd}{\nobreakdash}%
%\newcommand*{\bd}{\hspace{0pt}}%
%\def\hy{-\penalty0\hskip0pt\relax}
\newcommand*{\labelbis}[1]{\tag*{(\ref{#1})$_\text{r}$}}
%\newcommand*{\mathbox}[2][.8]{\parbox[t]{#1\columnwidth}{#2}}
%\newcommand*{\zerob}[1]{\makebox[0pt][l]{#1}}
%\newcommand*{\tprod}{\mathop{\textstyle\prod}\nolimits}
%\newcommand*{\tsum}{\mathop{\textstyle\sum}\nolimits}
%\newcommand*{\tint}{\begingroup\textstyle\int\endgroup\nolimits}
%\newcommand*{\tland}{\mathop{\textstyle\bigwedge}\nolimits}
%\newcommand*{\tlor}{\mathop{\textstyle\bigvee}\nolimits}
%\newcommand*{\sprod}{\mathop{\textstyle\prod}}
%\newcommand*{\ssum}{\mathop{\textstyle\sum}}
%\newcommand*{\sint}{\begingroup\textstyle\int\endgroup}
%\newcommand*{\sland}{\mathop{\textstyle\bigwedge}}
%\newcommand*{\slor}{\mathop{\textstyle\bigvee}}
\newcommand*{\T}{^\intercal}%transpose
\newcommand*{\E}{\mathrm{E}}
\DeclarePairedDelimiter\expp{(}{)}
\newcommand*{\expe}{\E\expp}%round
\newcommand*{\expeb}{\E\clcl}%square
%%\newcommand*{\QEM}%{\textnormal{$\Box$}}%{\ding{167}}
%\newcommand*{\qem}{\leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill
%\quad\hbox{\QEM}}

\newtheoremstyle{simple}%
{}%.5\baselineskip plusminus.2\baselineskip % \parsep
{}%
{\footnotesize}%
{}%
{}%
{}%
{0pt}%
{}%
\theoremstyle{simple}
\newtheorem*{simplenote}{}

\definecolor{notecolour}{RGB}{68,170,153}
\newcommand*{\puzzle}{{\fontencoding{U}\fontfamily{fontawesometwo}\selectfont\symbol{225}}}
\newcommand{\mynote}[1]{ {\color{notecolour}\puzzle\ #1}}
\newcommand*{\widebar}[1]{{\mkern1.5mu\skew{2}\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}}

\newcommand*{\av}{\widebar} %pop average
\newcommand*{\sav}{\widebar} %subpop average

\newcommand*{\ypp}{\varPi}

\newcommand*{\yxx}{x}%subpop state
\newcommand*{\yx}{\bm{\yxx}}%subpop state
\newcommand*{\yxs}{\sav{\yx}}%subpop av state
\newcommand*{\yX}{\bm{X}}%pop state
\newcommand*{\yy}{\bm{y}}%pop state
\newcommand*{\yXf}{\av{\yX}}%pop av state
\newcommand*{\yxxs}{\sav{\yx\yx}}%subpop av state
\newcommand*{\yXXf}{\av{\yX\yX}}%subpop av state
\newcommand*{\yr}{\bm{r}}%subpop value
\newcommand*{\ys}{\bm{s}}%subpop value
\newcommand*{\yrs}{\sav{\yr}}%subpop av value
\newcommand*{\yR}{\bm{R}}%pop value
\newcommand*{\yRf}{\av{\yR}}%pop av value
%conditional assumptions
\newcommand*{\yH}{\varIota}
\newcommand*{\yD}{\varDelta}
\newcommand*{\yHa}{\varIota'}
\newcommand*{\yHb}{\varIota''}
\newcommand*{\yHc}{\varKappa}
\newcommand*{\yHd}{\varUpsilon}
%Lagr multipliers
\newcommand*{\yf}{\bm{f}}
\newcommand*{\yc}{\bm{c}}
\newcommand*{\yL}{\bm{\varLambda}}
\newcommand*{\yl}{\bm{\lambda}}
\newcommand*{\yk}{\kappa}
\newcommand*{\yK}{\varKappa}
%entropies
\newcommand*{\ysh}{H}
\newcommand*{\ybu}{H_{\text{B}}}

\newcommand*{\prop}[1]{`#1'}

\newcommand*{\mee}{maximum entropy}
\newcommand*{\me}{maximum-entropy}

%@@@@@@@@@@ new macros end @@@@@@@@@@

\selectlanguage{british}\frenchspacing


\title{\pdftitle}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  P.G.L. Porta Mana\thanks{Equally contributing first authors}\\Independent researcher\\\texttt{pgl@portamana.org}
  \And
  V. Rostami$^*$\\Forschungszentrum J{\"u}lich INM-6\\Germany\\\texttt{v.rostami@fz-juelich.de}
  \And
E. Torre\\ETH Z{\"u}rich\\Switzerland\\
\texttt{torre@ibk.baug.ethz.ch}
  % David S.~Hippocampus\thanks{Use footnote for providing further
  %   information about author (webpage, alternative
  %   address)---\emph{not} for acknowledging funding agencies.} \\
  % Department of Computer Science\\
  % Cranberry-Lemon University\\
  % Pittsburgh, PA 15213 \\
  % \texttt{hippo@cs.cranberry-lemon.edu} \\
  %% examples of more authors
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
  This note has three nested purposes. The first purpose is to show that
  the \me\ method can be applied to a representative random sample of a
  population, to generate its probability distribution, along two different
  routes. Both routes appear legitimate, but they give inequivalent
  results. Which route should be chosen? Some arguments are presented in
  favour of one. The second more general purpose, motivated by the above
  dilemma, is to remind readers that models like \me\ may contain hidden
  assumptions; in this case the hidden an unnatural assumption that the
  sample modelled is isolated from the rest of the population. The third
  purpose is to promote some old but possibly forgotten probability
  formulae that may be useful in neuroscientific sampling contexts.
  % The abstract must be limited to one paragraph.
\end{abstract}

%\section{Implicit assumptions in the maximum-entropy method}
\section{Introduction: \me\ and sampling in neuroscience}

% LM: I'd like to avoid common beginnings like "Today blah blah is
% important" or "Blah blah is interesting/fundamental". They feel more like
% a mechanical ritual than a real tentative of connecting with the reader.
This note is mainly addressed to neuroscientists interested in \me\
methods, but we would be pleased if its discussion of the probability of
\enquote{random sampling} were useful to neuroscientists that use other
statistical methods to study the physical and dynamical characteristics of
brain areas via neuronal recording.

Recent electrophysiological techniques \cite{berenyietal2014} in fact allow
experimenters to record samples of even a couple hundreds neurons from
specific brain areas. These samples are usually picked out according to an
unknown process, but from their observation we expect to learn something
about all other neurons in the same brain area. That is, we assumed
that they are a \enquote{representative random sample}.

We don't elaborate on the various important purposes of such recordings
here \cite{?***}, but stress that these sample sizes can be considered
\enquote{large}, because their statistical analysis requires considerable
computational power.

These computational costs are one, probably not the earliest, of the many
reasons why \me\ methods have been introduced in neuroscience. It would be
useful to somehow compress the statistical wealth of large neuronal
recordings into few quantities, like sample moments for example. This
compression would also entail interesting physico-biological properties of
neuronal activity. The standard \me\ method
\cite{jaynes1957,sivia1996_r2006,meadetal1984} accomplishes this kind of
compression: it associates a unique probability distribution with few
experimental quantities \cite{***}.
But this is only one of its uses. It is
also used for various information-theoretic purposes or to generate
reference probability distributions \cite{schneidmanetal2006,shlensetal2006,roudietal2009b,tkaciketal2014b}.
In all these uses the \me\
distribution is chosen as the \enquote{maximally noncommittal} one
\cite{jaynes1963}. This adjective means little without further technical
characterizations. Different works give different characterizations, but in
this paper we will use the quoted expression as an umbrella term for all of
them. Our results will not depend on the specific characterization of
\enquote{noncommittal}.

\bigskip

In this note we want to show that we have to face a dilemma if we want to
apply the \me\ method to a representative random sample to find a maximally
noncommittal distribution.

The dilemma is this. We can apply the \me\ method to the sample, using a
specified set of experimental constraints, and generate a probability
distribution for its state. But our sample is representative of a larger
population. We can apply the \me\ method to the larger population, using
the same constraints, and generate a probability distribution for its
larger state, and then find the distribution for the sample by
marginalization. Either application seems to have some commendable
features. However, \emph{the distributions obtained by these two
  applications differ}. It goes without saying that if one is
\enquote{maximally noncommittal}, the other must be somehow
\enquote{committal}. Which choice is most meaningful?


In the rest of the paper we mathematically formulate this dilemma. To this
purpose we also present some probability relations relevant to
\enquote{random sampling}. These relations are well-known in survey
sampling and in the pedagogic problem of drawing from an urn without
replacement, yet they are somewhat hard to find explicitly written in the
neuroscientific literature, so they may be of interest on their own. 

In the final discussion we present some arguments in favour of one choice
in our dilemma, but we do not mean that to be our final answer. This note,
and its dilemma,  also have the more general purpose of reminding our
readers the importance of asking \emph{what is the question we're trying to
  answer with probability theory?} and \emph{which assumptions do we want
  or need to make?}

Our mathematical analysis pertains to a neurons modelled as binary units at
one specific instant or short window in time. It is possible to similarly
discuss multi-state neuron models and population dynamics; but for
simplicity neurons are here assumed to be in a fixed, active \enquote{$1$}
or inactive \enquote{$0$} state; and evolution, change, time correlations,
and similar concepts do not concern us. We consider \me\ models that have
constraints based on some kinds of sample or population averages; they are
often called \enquote{homogeneous}. The final discussion touches upon
\enquote{inhomogeneous} models as well.


The notation in this note follows ISO and ANSI standards
\citep{iso1993,ieee1993,nist1995} but for the use of the comma \enquote{,}
to denote logical conjunction. Probability notation follows Jaynes
\citep{jaynes1994_r2003}. By \enquote{probability} we mean plausibility or
the degree of belief which \enquote{would be agreed by all rational men if
  there were any rational men} \cite{good1966}.

\section{Setup}
\label{sec:setup}

We have a population of $N$ binary neurons. We assume that they can be
distinguished, by their spike shapes for example; but other details, like
their locations, are unknown. The neurons have a joint state
$(X_1,\dotsc,X_N) \defs \yX$ having fixed but unknown binary values
$(R_1,\dotsc,R_N)\defs \yR \in \set{0,1}^N$. A particular sample of $n$
neurons from this population has joint state $(x_1, \dotsc, x_n) \defs \yx$
having fixed binary values $(r_1, \dotsc, r_n)\defs\yr$. We will consider
various averages of the population and the sample. For this purpose we
introduce a general averaging operator $\sav{\dotv}$ defined by
\begin{equation}
  \begin{gathered}
    \av{\yX} \defd \tfrac{1}{N} (X_1 + X_2 + \dotsb + X_N),
    % & \sav{\yx} &\defd \tfrac{1}{n} (x_1 + x_2 + \dotsb + x_n),
   \qquad% \\[2\jot]
    \av{\yX \yX} \defd \tbinom{N}{2}^{-1} (X_1 X_2 + X_1 X_3 + \dotsb +
    X_{N-1} X_N),
    % & \sav{\yx \yx} &\defd\tbinom{n}{2}^{-1} (x_1 x_2 + x_1 x_3 + \dotsb
    % + x_{n-1} x_n),
    \\[2\jot]
    \av{\yX\yX\yX} \defd \tbinom{N}{3}^{-1} (X_1 X_2 X_3 +% X_1 X_2 X_4
    \dotsb + X_{N-2} X_{N-1}X_N),
    % & \sav{\yx\yx\yx} &\defd \tbinom{n}{3}^{-1} (x_1 x_2 x_3
    % + %x_1 x_2 x_4
    % \dotsb + x_{n-2} x_{n-1} x_n),
  \end{gathered}
\end{equation}
and so on.
These formulae say that $\yXf$ is the fraction of active neurons, $\yXXf$
the fraction of simultaneously active pairs out of all $\binom{N}{2}$
pairs, $\av{\yX\yX\yX}$ the fraction of simultaneously active triplets, and
so on. Products of states like $X_i \dotsm X_j$ also have values in
$\set{0,1}$; from this we can combinatorially  prove that
\begin{equation}
  \label{eq:products_intermsof_average}
  \av{\underbrace{\yX\dotsm\yX}_{\text{$m$ factors}}}
  = \binom{N}{m}^{-1}\binom{N\yXf}{m}.
\end{equation}
Analogous formulae  hold for quantities like $\yx$, $\yR$, $\yr$.

\iffalse
\begin{simplenote}
  \mynote{Remove this} A sample can be \enquote{random} in two different
  ways. Consider the population of neurons named $\set{1,2,3}$ for example.
  The sample $\set{1,3}$ is random because neurons $1$ and $3$ were chosen
  according to an unknown process. The sample
  $\set{\textrm{X}_1, \textrm{X}_2}$ is random because we don't know the
  identity of neurons $\textrm{X}_1$ and $\textrm{X}_2$. Given the
  probability for the population, the probabilities for the states of these
  two samples are different: the former is obtained by marginalization, the
  latter by symmetrization and marginalization.
\end{simplenote}
\fi

Our uncertainty about the actual state of the population is completely
expressed by the joint probability distribution
\begin{equation}
  \label{eq:joint_plaus}
  \p(X_1=R_1, X_2=R_2, \dotsc, X_N=R_N \| \yHc) \quad\text{or}\quad
\p(\yX =\yR \| \yHc), \quad \yR \in \set{0,1}^N,
\end{equation}
where $\yHc$ denotes our state of knowledge, \ie\ the evidence and
assumptions backing this particular probability assignment. Our uncertainty
about the state of the sample is likewise expressed by
\begin{equation}
  \label{eq:sample_plaus}
  \p(x_1=r_1, x_2=r_2, \dotsc, x_n=r_n \| \yHc) \quad\text{or}\quad
\p(\yx =\yr \| \yHc), \quad \yr \in \set{0,1}^n.
\end{equation}



\section{Initial assumptions: the probability of representative samples}
\label{sec:prob_samples}

We need to make an initial probability assignment before any experimental
observations are
made. %, no matter what kinds of predictions we are interested in.
This initial assignment will be modified by our experimental observations.
We would also like our probability assignment to reflect that the sample is
somehow \enquote{representative} of the population.

Let's assume that we initially know very little about the physical details
of the individual neurons; their locations for example. Our initial state
of knowledge or ignorance $\yH$ is therefore symmetric, or
\enquote{exchangeable}, under their permutations. This symmetry must be
reflected in our initial probability: the \emph{representation theorem for
  finite exchangeability} states that it must obey
\begin{equation}
  \label{eq:joint_plaus_N_homog}
  \p(\yX = \yR \| \yH) = \binom{N}{N\yRf}^{-1} \p(\yXf=\yRf \| \yH),
\end{equation}
the latter being the probability for the population average $\yX$. Proof of
this theorem and generalizations to non-binary and continuum cases are
given by de~Finetti \cite{definetti1959b}, Ericson \cite{ericson1976},
Diaconis \cite{diaconis1977}, Heath \amp\ Sudderth \cite{heathetal1976}.
This theorem is intuitive: owing to symmetry, we must assign equal
probabilities to all states with $N\yRf$ active neurons.

By marginalization we obtain the probability for the state of the sample:
\begin{gather}
  \label{eq:marginal}
  \p(\yx = \yr \| \yH) = \binom{n}{n\yrs}^{-1} \p(\yxs=\yrs \| \yH),
  \\
  \shortintertext{with}
  \label{eq:subpop_average}
  \p(\yxs=\yrs \| \yH) = \sum_{N \yRf =0}^{N}
    \p(\yxs = \yrs \|\yXf=\yRf, \yH)\,
  \p(\yXf=\yRf \| \yH),
  \\[2\jot]
  \label{eq:conditional_hypergeometric}
  \p(\yxs = \yrs \|\yXf=\yRf, \yH)=
  \binom{n}{n\yrs}\binom{N-n}{N \yRf-n\yrs}\binom{N}{N \yRf}^{-1}
  \defs \ypp(\yrs\|\yRf).
\end{gather}
Our initial symmetric ignorance should intuitively also apply to the
sample; indeed, the probability for the state of the
sample~\eqref{eq:subpop_average} automatically satisfies the representation
theorem~\eqref{eq:joint_plaus_N_homog} as well. The conditional probability
in the last formula is a hypergeometric distribution $\ypp(\yrs\|\yRf)$,
typical of \enquote{drawing without replacement} problems. The
combinatorial proof of the formulae above is in fact the same as for this
class of problems
\cites[\chap~3]{jaynes1994_r2003}[\sect~4.8.3]{ross1976_r2010}[\sect~II.6]{feller1950_r1968}.

The conditional probability $\ypp(\yrs,\yRf)$ relates the spaces of the
sample average $\yXf\in\set{0,\dotsc,N}$ and of the population average
$\yxs\in\set{0,\dotsc,n}$ in a special way. It is a coarsening projector of
any probability $p$ for $\yXf$ onto a marginal probability $p_*$ for
$\yxs$:
\begin{equation}
  \label{eq:projection_P}
  % \ypp\colon p(\yXf=\dotv) \to
  p_*(\yxs=\yrs)
  = \sum_{N\yRf=0}^N \ypp(\yrs\|\yRf) p(\yXf=\yRf).
\end{equation}
Conversely it also a pulls back expectations of functions $f$ of the sample
average $\yxs$ to expectations of functions $f^*$ of the population average
$\yXf$:
\begin{equation}
  \label{eq:pullback_P}
%  \ypp^*\colon f(\yxs=\dotv) \to f^*(\yXf=\dotv) \defd \sum_{N\yrs=0}^n
%  f(\yrs)\ypp(\yrs\|\dotv),
  \begin{gathered}
    f^*(\yXf) \defd \sum_{n\yrs=0}^n f(\yrs)\ypp(\yrs\|\yXf),
    \\
   \expeb{f(\yxs)}= \expeb{f^*(\yXf)}
    =
    \sum_{n\yrs=0}^n f(\yrs)\,\p(\yxs=\yrs \| \yH)
    =
    \sum_{N\yRf=0}^N f^*(\yRf)\,\p(\yXf=\yRf \| \yH).
  \end{gathered}
\end{equation}


\begin{figure}[!t]
\centering
\includegraphics[width=0.99\linewidth]{pop_sample_projection3.pdf}%
\caption{Log-plot of the hypergeometric distribution
  $%\p(\yxs = \yrs \|\yXf=\yRf, \yH)=
\ypp(\yrs\|\yRf) \defd  \binom{n}{n\yrs}\binom{N-n}{N \yRf-n\yrs}\binom{N}{N \yRf}^{-1}$ for $N=5000$, $n=200$. (Band artifacts may appear in the
  colourbar depending on your \textsc{pdf} viewer.)}
\label{fig:hypergeom_proj}
\end{figure}%hypergeometric_identity.nb
A look at a plot of the hypergeometric distribution $\ypp(\yrs\|\yRf)$, see
\fig~\ref{fig:hypergeom_proj}, reveals that it is a sort of \enquote{fuzzy
  identity matrix} between the $\yXf$-space $\set{0,\dotsc,N}$ and
$\yxs$-space $\set{0,\dotsc,n}$. When $n=N$ it is the identity matrix. We
thus have that
\begin{equation}
  \label{eq:roughly_equal_nN}
  \p(\yxs=a) \approx \p(\yXf=a),\qquad
\expeb{f(\yxs)} \approx \expeb{f(\yXf)}.
\end{equation}
These are only very approximate equalities: they may miss important
features of the two probability distributions. In the next section we will
in fact emphasize their differences. If the distribution for the population
average $\yXf$ is bimodal, for example, the bimodality can be lost in the
distribution for the sample average $\yxs$, owing to the coarsening effect
of $\ypp(\yrs\|\yRf)$.

Yet, the approximate equalities above express the fact that \emph{our
  uncertainty about the sample is representative of our uncertainty about
  the population and about other samples}, and vice versa. This is how the
idea of representativeness is translated into our probabilities. The
symmetry present in our initial probabilities is not a physical property of
the neuronal population or sample. It only expresses the symmetry of our
initial uncertainty about them, and does not imply any sort of physical
similarity between the neurons. Subsequent observations may in fact break
this symmetry. Upon observation of a sample average, say $\yxxs=a$, the
updated expectations for such average in the population and in any new
sample will usually be shifted towards the observed value, as follows from
Bayes's theorem and the formulae above.


Note that formulae~\eqref{eq:roughly_equal_nN} say more than the limits
$\p(\yxs=a) \to \p(\yXf=a)$, $\expeb{f(\yxs)} \to \expeb{f(\yXf)}$ as
$n\to N$. These limits are trivially valid because the sample becomes the
full population as $n\to N$. In particular, these limits hold even in cases
where the conditional probability $\p(\yxs = \yrs \|\yXf=\yRf)$ is not a
fuzzy identity and our uncertainties about sample and about population can
differ wildly.


\bigskip

% The projection~\eqref{eq:projection_P} and pull-back~\eqref{eq:pullback_P}
% have the property
% \begin{equation}
%   \label{eq:expectation_pullback}
%   \expeb{f(\yxs) \|\yH} = \expeb{f^*(\yXf)\|\yH}
%   \qquad\text{or}\qquad
%   \sum_{n\yrs=0}^n f(\yrs)\,p_*(\yxs=\yrs) = \sum_{N\yRf=0}^N f^*(\yRf)\,p(\yXf=\yRf).
% \end{equation}
For functions representing averaged products,
$f(\yxs) \defd \sav{\yx\dots\yx}=\binom{n\yxs}{m}/\binom{n}{m}$,
formulae~\eqref{eq:pullback_P} have the useful form
\begin{equation}
  \label{eq:expe_products}
%  \label{eq:pullback_m_expectations}
%  \ypp^*\colon \sav{\underbrace{\yx \dotsm \yx}_{\text{$m$ factors}}}
%  \mapsto
  \begin{gathered}
    \bigl( \sav{\underbrace{\yx \dotsm \yx}_{\text{$m$ factors}}}\bigr)^* =
    \av{\underbrace{\yX \dotsm \yX}_{\text{$m$ factors}}},
    \\[2\jot]
    % \expe{\sav{\underbrace{\yx \dotsm \yx}_{\text{$m$ factors}}} \| \yH} =
    % \expe{\av{\underbrace{\yX \dotsm \yX}_{\text{$m$ factors}}} \| \yH}
    \expe{\sav{\yx \dotsm \yx} \| \yH} =
    \expe{\av{\yX \dotsm \yX} \| \yH}
    % \\[2\jot]
    % {}
    = \binom{n}{m}^{-1}
    % \frac{(n-m)!}{n!}
    \sum_{\mathclap{n \yrs=0}}^n %m!\,
    \binom{n \yrs}{m}\, \p(\yxs=\yrs \| \yH)
    % \sum_{N \yRf=0}^N %m!\,
    % \binom{N-m}{N \yRf-m} \binom{N}{N \yRf}^{-1} \p(\yXf=\yRf \| \yH)
    = \binom{N}{m}^{-1}
    % \frac{(N-m)!}{N!}
    \sum_{\mathclap{N \yRf=0}}^N %m!\,
    \binom{N \yRf}{m}\, \p(\yXf=\yRf \| \yH).
  \end{gathered}
\end{equation}
The proof uses the expression for the $m$th factorial moment of the
hypergeometric distribution \cite{potts1953}. Thus, the averages of
activity products \emph{are the same for the sample and for the full
  population}. Similar relations can be found for the raw moments
$\expe{\yxs^m}$ and $\expe{\yXf^m}$, which can be written in terms of the
product expectations via \eqn~\eqref{eq:products_intermsof_average}.





\section{Enter maximum-entropy: dilemma}
\label{sec:specific_initial_probability}

Formulae
\eqref{eq:joint_plaus_N_homog}--\eqref{eq:conditional_hypergeometric} are
constraints on our initial probability assignment, but do not determine it
numerically. The probability $\p(\yXf=\yRf \| \yH)$ for the population
average needs to be numerically specified, and by \eqref{eq:subpop_average}
it will determine that of the sample average, $\p(\yxs=\yrs \| \yH)$. If we
numerically specify the latter, the former is not completely specified,
because \eqn~\eqref{eq:subpop_average} linearly constrains $N+1$ unknowns
by only $n+1$ equations in this case.

We may want to specify the probability by enforcing the sample expectations
of several functions to have specific values, for example
$\expe{\yxs}=c_1$, $\expe{\yxxs}=c_2$. This is still an underdetermined
linear problem: several distributions can have the same desired
expectations, as clear from \eqns~\eqref{eq:expe_products}.

The \me\ method is brought into play to solve this indeterminacy. It
selects one distribution, purported to be \enquote{maximally noncommittal},
among those that have the desired expectations. But here's a dilemma:
formulae~\eqref{eq:pullback_P} allow us to apply the method to find the
probability of the population $\p(\yXf=\yRf \| \yH)$, or of the sample
$\p(\yxs=\yrs \| \yH)$. \emph{The two applications, however, are
  inequivalent}. They lead to numerically different $\p(\yxs=\yrs \| \yH)$.

Suppose we want to constrain the sample expectations of a vector function
$\yf = (f_1,\dotsc,f_m)$ to the vector values $\yc=(c_1,\dotsc,c_m)$, that
is, $\expeb{\yf(\yxs)}=\yc$. Application of \me\ at the population level,
denoted by $\yHa$, gives
\begin{equation}
  \label{eq:app_maxent_pop}
  \p(\yXf = \yRf \| \yHa)  = \yK\,
  \binom{N}{N \yRf}\exp\Bigl[\yL\T
  \sum_{n\yrs=0}^n \yf(\yrs)\ypp(\yrs\|\yRf)\Bigr],
\end{equation}
and then by marginalization with \eqn~\eqref{eq:marginal}
\begin{equation}
  \label{eq:app_maxent_pop_marg}
  \p(\yxs = \yrs \| \yHa)  = \yK\, 
  \sum_{N\yRf=0}^N \ypp(\yrs \|\yRf)
\,
  \binom{N}{N \yRf}\exp\Bigl[\yL\T
  \sum_{n\yrs=0}^n \yf(\yrs)\ypp(\yrs\|\yRf)\Bigr],
\end{equation}
where $\yK$ is a normalization constant and
$\yL\T=(\varLambda_1,\dotsc,\varLambda_m)\T$ are Lagrange multipliers such
that
\begin{equation}
  \label{eq:app_maxent_pop_constraints}
\yc = \yK\sum_{n\yrs=0}^n \sum_{N\yRf=0}^N \yf(\yrs) \ypp(\yrs \|\yRf)
\,
  \binom{N}{N \yRf}\exp\Bigl[\yL\T
  \sum_{n\yrs=0}^n \yf(\yrs)\ypp(\yrs\|\yRf)\Bigr].
\end{equation}
Application of \me\ at the sample level, denoted by $\yHb$, gives
\begin{equation}
  \label{eq:app_maxent_sample}
  \p(\yxs=\yrs \|\yHb)
  =\yk\,
  \binom{n}{n\yrs}
  \exp[\yl\T \yf(\yrs)]
\end{equation}
where $\yk$ is a normalization constant and $\yl\T$ are Lagrange
multipliers such that
\begin{equation}
  \label{eq:app_maxent_sample_constraints}
\yc = \yk\sum_{n\yrs=0}^n  \yf(\yrs) \binom{n}{n\yrs}
  \exp[\yl\T \yf(\yrs)].
\end{equation}

The probabilities for the sample average obtained from application at the
population level~\eqref{eq:app_maxent_pop_marg} and at the sample level
\eqref{eq:app_maxent_sample} should be approximately equal, by our previous
observation about representativity~\eqref{eq:roughly_equal_nN} and also by
the fact that they must satisfy the same expectations for $\yf$.

Yet they cannot be exactly equal, because their equality would require the
Lagrange multipliers $\yL$ and $\yl$ to satisfy equations
\eqref{eq:app_maxent_pop_constraints},
\eqref{eq:app_maxent_sample_constraints}, and
$\p(\yxs = \yrs \| \yHa) = \p(\yxs = \yrs \| \yHb)$ -- that is, $2m+n$
equations in $m$ unknowns. This could be possible, if at all, only for very
special choices of constraints functions $\yf$ and values $\yc$.

The sample distribution obtained from \me\ at the sample level will
therefore likely miss important features present in the one obtained at the
population level, like additional modes or particular tail behaviour.


\begin{figure}[!t]
\centering
\includegraphics[width=0.99\linewidth]{different_maxent_pop_sample_200_realdata_2mom.pdf}%
\caption{Linear and log-plots of $\p(\yxs = \yrs)$ constructed by \me\ at the population
  level followed by sample marginalization (blue triangles),
  \eqn~\eqref{eq:app_maxent_pop_marg}, and at the sample level (red
  circles), \eqn~\eqref{eq:app_maxent_sample}, with $N=5000$,
  $n=200$, constraints $\expe{\yxs}=0.0478$, $\expe{\yxxs}=0.00257$.}
\label{fig:diff_maxent_pop_sample}
\end{figure}%maxent_pop_or_sample.nb
% \end{wrapfigure}
\begin{figure}[!t]
\centering
\includegraphics[width=0.99\linewidth]{different_maxent_pop_sample_200_realdata_4mom.pdf}
% 
\caption{Linear and log-plots of $\p(\yxs = \yrs)$ constructed by \me\ at
  the population level followed by sample marginalization (blue triangles),
  \eqn~\eqref{eq:app_maxent_pop_marg}, and at the sample level (red
  circles), \eqn~\eqref{eq:app_maxent_sample}, with $N=5000$,
  $n=200$, constraints $\expe{\yxs}=0.0478$, $\expe{\yxxs}=0.00257$,
  $\expe{\sav{\yx\yx\yx}}=1.48\times10^{-4}$,
  $\expe{\sav{\yx\yx\yx\yx}}=8.81\times 10^{-6}$.}
\label{fig:diff_maxent_pop_sample_realdata}
\end{figure}%maxent_pop_or_sample.nb
We show two examples of this discrepancy in
\figs~\ref{fig:diff_maxent_pop_sample}
and~\ref{fig:diff_maxent_pop_sample_realdata}, for $N=5000$, $n=200$, and
constraint functions of the form
$\yf(\yxs)=(\yxs,\yxxs,\dotsc)\equiv\bigl(
\yxs, \raisebox{0pt}[0pt][1ex]{}\binom{n\yxs}{2}/\binom{n}{2},\dotsc \bigr)$. In the first example the
constraints are $\expe{\yxs} = c_1$ and $\expe{\yxxs} = c_2$, with
$c_1=0.0478$ and $c_2=0.00257$. The distribution obtained at the sample
level is broader than the one obtained at the population level; the tails
of the two distributions are very different. The second example includes
two additional constraints $\expe{\sav{\yx\yx\yx}}= c_3$,
$\expe{\sav{\yx\yx\yx\yx}}=c_4$ with $c_3=0.000148$,
$c_4=8.81\times 10^{-6}$. The distribution obtained at the population level
has two modes, replaced by only one in the distribution obtained at the
sample level; the tails are very different also in this case. The
constraints used in these examples have neurobiologically realistic values
\cite{rostamietal2016}.



\bigskip

How should we apply the \me\ method then? on the sample or on the
population? Which application is maximally noncommittal?

\section{Discussion}
\label{sec:discussion}

The question that closed the preceding section cannot receive a categorical
answer. An optimal answer can only be given case by case, depending on the
computational power available, on which inferences we are trying to make,
on which assumptions we need or want to make and those we wish to avoid.

\iffalse We want to stress, in fact, the
extreme importance and priority of the following two questions:
\begin{itemize}
\item Of which quantities do we need to quantify the uncertainty? and why?
\item What are the assumptions we need or want to make to answer the
  question above?
\end{itemize}\fi

The first purpose of this note is indeed to remind ourselves that
probability models require careful scrutiny, because they can rest on
hidden assumptions that we don't want to make or that contradict others we
are making, and we may not be aware of this. The dilemma generated by the
\me\ method and the assumption of representative sampling is an example.

The tricky point is this. Maximum-entropy applied at the population level
and applied at the sample level give different results; they are different
statistical models. The former model clearly assumes, by construction, the
existence of a larger population from which the sample is taken. What does
the latter model assume in this respect? is it \enquote{unassuming}, as
often claimed in the literature? or is it actually assuming that \emph{no}
larger population exists? In the latter case it would not be the correct
model to use in our problem.

A perfunctory intuitive reasoning seems insufficient for clarifying this
point. Let's express it via the probability calculus. Suppose we do not
know whether the sample is really part of a larger population; we do not
know if $N=n$ or how large is $N$ otherwise. Call this state of ignorance
$\yHd$. From the point of view of the probability calculus, this ignorance
about $N$ is expressed by assigning a probability distribution
$\p(N \| \yHd)$ that vanishes if $N<n$, since we know that $N\ge n$.
Maintaining our assumption of symmetric ignorance, probability assignments
that do not assume a specific value of $N$ are then obtained by
multiplication of all $N$-dependent probabilities by $\p(N \| \yHd)$ and
subsequent marginalization over $N$ -- technically speaking, $N$ is a
\emph{nuisance parameter} that we eliminate. The probability obtained from
\me\ at the population level, \eqn~\eqref{eq:app_maxent_pop_marg} then
generalizes to
\begin{equation}
  \label{eq:app_maxent_pop_marg_unknown_N}
  \p(\yxs = \yrs \| \yHd)  = \sum_N \biggl\{\yK_N\, 
  \sum_{N\yRf=0}^N \ypp_N(\yrs \|\yRf)
\,
  \binom{N}{N \yRf}\exp\Bigl[{\yL_N}\T
  \sum_{n\yrs=0}^n \yf(\yrs)\ypp_N(\yrs\|\yRf)\Bigr]\biggr\}
  \,\p(N \| \yHd).
\end{equation}
This is a formidable expression. But the answer to our question, whether
the usual \me\ at the sample level~\eqref{eq:app_maxent_sample} does not
assume anything about a larger population, translates into the precise
mathematical question: are the
distributions~\eqref{eq:app_maxent_pop_marg_unknown_N} and
\eqref{eq:app_maxent_sample} equal, for some choice of $\p(N \| \yHd)$? We
leave this mathematical problem for future work.


\iffalse
The former application must therefore implicitly assume that no
larger population exist, or that the neurons of the sample are isolated
from their environment.

The \me\ application at the population level gives in fact, by
construction, a distribution with lower Shannon relative entropy than the
one given by the application at the sample level: both satisfy the same
constraints, but only the latter is obtained by direct maximization of the
entropy. The lower entropy of the distribution obtained from application at
the population level is clearly visible from its higher sharpness in
\fig~\ref{fig:diff_maxent_pop_sample}. Such distribution therefore
excludes, probabilistically speaking, more sample states $\yx$ than the
distribution obtained at the sample level does. A lower entropy signals the
presence of additional assumptions or constraints. In this case the
assumption is that the sample is part of a larger population, and our
ignorance about the sample should be representative of our ignorance about
a larger population. This assumption affects our predictions.
\fi

In a neuroscientific context we find this assumption very natural, and
therefore the \me\ method at the population level preferable. After all,
also \emph{physical} neuronal-network models usually include some sort of
external input to the neurons, mimicking their embedding in a larger
network.

\iffalse
The quandary we found in the present note has at least two bright sides.
The first is that the two different \me\ applications may give numerically
similar results in some cases. One could thus be used as an approximation
of the other, depending on the circumstances -- \eg\ if probability tails
are unimportant. See \fig~\ref{fig:diff_maxent_pop_sample_realdata} for an
example.
\begin{figure}[!t]
\centering
\includegraphics[width=0.95\columnwidth]{different_maxent_pop_sample_200_realdata_both.pdf}
% 
\caption{Example of discrepancy in $\p(\yxs = \yrs \| \yH)$ constructed by
  \me\ at the population level followed by sample marginalization (blue
  triangles), and at the sample level (red circles). The constraints are
  the same in either case: $\expe{\yxs \|\yH}=0.045$,
  $\expe{\yxxs \|\yH}=0.0025$, and $N=5000$, $n=200$.}
\label{fig:diff_maxent_pop_sample_realdata}
\end{figure}%maxent_pop_or_sample.nb
The second is that \fi The possibility of using two different distributions
is not a physical contradiction. Similar situations arise in statistical
mechanics. It is known that if a system is described by a \me\ Gibbs state,
its subsystems need not be \cite{maesetal1999}. A dilemma quite similar to
ours also appears in the statistical description of the final state of a
non-equilibrium process starting and ending in two equilibrium states: we
can describe our knowledge about the final state either by a Gibbs
distribution, or by the distribution obtained from the Liouville evolution
of the Gibbs distribution assigned to the initial state. The two
descriptions differ -- even though the final \emph{physical} state is
obviously exactly the same \cite[\sect~4]{jaynes1985d_r1993}. The
difference in the two descriptions appears because in one case we can make
sharper predictions about the state thanks to our knowledge of its
preceding dynamics. In this example, though, both distributions are usually
immensely sharp and practically lead to the same predictions. In the cases
considered in this note the difference in predictions may be relevant, and
the ones made by \me\ at the population level are more informed.

\mynote{Importance of the formulae relating sample and population.}

\mynote{Discussion of case when individual $X_i\dotsm X_j$ are constrained.
Likely breakdown of \me\ in this case \cite{portamana2009}. Hints at full
Bayesian treatment of which \me\ is a limit? \cite[***]{mackay1995_r2003}}


% do not change font sizes (except perhaps in the \textbf{References}
% section; see below).


\subsubsection*{Acknowledgments}

To be added after review.
\iffalse PGLPM thanks Mari \amp\ Miri for continuous encouragement and affection,
Buster Keaton for filling life with awe and inspiration, and the developers
and maintainers of \LaTeX, Emacs, AUC\TeX, MiK\TeX, arXiv, biorXiv,
PhilSci, Hal archives, Python, Inkscape, Sci-Hub for making a free and
unfiltered scientific exchange possible.\fi

% Use unnumbered third level headings for the acknowledgments. All
% acknowledgments go at the end of the paper. Do not include
% acknowledgments in the anonymized submission, only in the final paper.

%\section*{References}
\renewcommand*{\bibname}{References}
\defbibheading{bibliography}[\bibname]{\section*{#1}\addcontentsline{toc}{section}{#1}%\markboth{#1}{#1}
}

% References follow the acknowledgments. Use unnumbered first-level
% heading for the references. Any choice of citation style is acceptable
% as long as you are consistent. It is permissible to reduce the font
% size to \verb+small+ (9 point) when listing the references. {\bf
%   Remember that you can go over 8 pages as long as the subsequent ones contain
%   \emph{only} cited references.}
% \medskip

% \small

% [1] Alexander, J.A.\ \& Mozer, M.C.\ (1995) Template-based algorithms
% for connectionist rule extraction. In G.\ Tesauro, D.S.\ Touretzky and
% T.K.\ Leen (eds.), {\it Advances in Neural Information Processing
%   Systems 7}, pp.\ 609--616. Cambridge, MA: MIT Press.

% [2] Bower, J.M.\ \& Beeman, D.\ (1995) {\it The Book of GENESIS:
%   Exploring Realistic Neural Models with the GEneral NEural SImulation
%   System.}  New York: TELOS/Springer--Verlag.

% [3] Hasselmo, M.E., Schnell, E.\ \& Barkai, E.\ (1995) Dynamics of
% learning and recall at excitatory recurrent synapses and cholinergic
% modulation in rat hippocampal region CA3. {\it Journal of
%   Neuroscience} {\bf 15}(7):5249-5262.
\defbibnote{postnote}{\small\par\medskip\noindent{\footnotesize% Note:
\arxivp \mparcp \philscip \biorxivp}%
}

\newcommand*{\citein}[2][]{\textnormal{\textcite[#1]{#2}}%\addtocategory{extras}{#2}
}
\newcommand*{\citebi}[2][]{ref.\ \citep[#1]{#2}%\addtocategory{extras}{#2}
}
\newcommand*{\subtitleproc}[1]{}


\printbibliography[postnote=postnote]

\iffalse
\newrefsection
\bigskip
{\centering\mynote{*** From here down old text to be discarded ***}\par}
\section{***}

\begin{align}
  \expe{x_{i_1} \dotsm x_{i_m} \| \yH}
&=
\expe{\sav{\underbrace{\yx \dotsm \yx}_{\text{$m$ factors}}} \| \yH}
=
\expe{\av{\underbrace{\yX \dotsm \yX}_{\text{$m$ factors}}} \| \yH},
\\
\intertext{and has an explicit expression in terms of $Q$:}
  \begin{split}
\expe{x_{i_1} \dotsm x_{i_m} \| \yH}
&=
\binom{N}{m}^{-1}
%\frac{(N-m)!}{N!}
\sum_{N A=0}^N %m!\, 
\binom{N A}{m}\, Q(A)
\\
&\equiv
%\frac{(N-m)!}{N!}
\sum_{N A=0}^N %m!\, 
\binom{N-m}{N A-m}
\binom{N}{N A}^{-1} Q(A).
\end{split}
\end{align}
\end{subequations}


What do we mean by saying that we can learn something about the population
by observing the sample? At the very least we mean that our uncertainty
about the rest of the population can change upon observing the sample. That
is, the probability for the state $\yy$ of the rest of the population is
conditionally dependent on the sample's values:
\begin{equation}
  \label{eq:conditionally_dependent_sample}
  \p(\yy =\ys \| \yx=\yr,\yH) \ne \p(\yy =\ys \|\yH)
  \qquad\text{for some $\ys,\yr$},
\end{equation}
This also means that the probability for the population cannot be
factorized into that of the sample times that of the complement.

What do we mean when we say that the sample is representative of the
population? It means that we expect some collective properties of the
sample, like the fraction of active neurons, or the fraction of
simultaneously active pairs, to be roughly equal to those of the full
population.

***

For example, $\yX$ can
represent the state of a population at a particular time. We call the
neurons \enquote{units} to lend some generality to our discussion. We shall
make statements about the whole population of $N$ units and about a
subpopulation of $n$ units; the word \enquote{population} will always refer
to the \emph{whole} population. The subpopulation states and their values
are denoted by lowercase letters: $(x_1, \dotsc, x_n)\equiv\yx$ and
$(r_1, \dotsc, r_n)\equiv\yr$; but note that $x_i \equiv X_{j_i}$ and
$r_i \equiv R_{j_i}$ for some distinct $j_1,\dotsc,j_n$. We shall also make
statements about the population-averaged state, or \emph{population
  average}:
\begin{align}
  \label{noeq:population-av}
   \yXf &\defd (X_1 + \dotsb + X_N)/N,
\\
\intertext{and the subpopulation-averaged state, or \emph{subpopulation average}:}
\label{noeq:subpopulation-av}
\yxs &\defd (x_1 + \dotsc + x_n)/n.
\end{align}
The quantities $N\yXf$ and $n\yxs$ represent the total number of active
units in the population and the subpopulation. Quantities like $\yRf$ and $\yrs$
are defined analogously. The averaging operators $\sav{\dotv}$ and
$\av{\dotv}$ are also extended to averages of $\tbinom{n}{m}$ or
$\tbinom{N}{m}$ products of $m$ states; \eg,
\begin{align}
\av{\yX \yX} &\defd
\tbinom{N}{2}^{-1} (X_1 X_2 + X_1 X_3  + \dotsb +  X_{N-1} X_N),
\\[2\jot]
\sav{\yx\yx\yx} &\defd
\tbinom{n}{3}^{-1} (x_1 x_2 x_3 + x_1 x_2 x_4 + \dotsb + x_{n-2} x_{n-1} x_n),
\end{align}
and so on.


\subsection{Assumptions}
\label{nosec:assumptions}

Our uncertainty about the population state is represented by the joint
probability distribution of the individual states, from which we can
derive all other probabilities of interest. We denote it by
\begin{equation}
  \label{noeq:joint_plaus}
  \p(X_1=R_1, X_2=R_2, \dotsc, X_N=R_N \| \yH) \quad\text{or}\quad
\p(\yX =\yR \| \yH).
\end{equation}
Such probability is conditional on our state of knowledge, \ie\ the
evidence and assumptions backing our probability assignments, denoted by
the proposition $\yH$.

In the present discussion, $\yH$ is a state of knowledge that leads to two
specific properties in our probability assignments:

\medskip
\begin{enumerate}%[wide,label=$\yH$\arabic*.]
\item \emph{Permutation symmetry}, expressed as the invariance of the
  joint distribution~\eqref{noeq:joint_plaus} under arbitrary permutations of
  the units's labels:
\begin{multline}
  \label{noeq:homog_math}
  \p(X_1=R_1, X_2=R_2, \dotsc, X_N=R_N \| \yH) ={}
\\ 
\shoveright{\p(X_1=R_{\pi(1)}, X_2=R_{\pi(2)}, \dotsc, X_N=R_{\pi(N)} \| \yH)}
\\
\text{for any permutation $\pi$}.
\end{multline}
This property can reflect two very different states of knowledge: physical
homogeneity of the population, or symmetry in our ignorance about the population.
This property is called \emph{finite exchangeability} in the Bayesian
literature and its basis, consequences, and alternatives to it are discussed
in \sect~***%\ref{nosec:stoch_symm}.

\medskip

\item The population average $\yXf$ has a particular distribution $Q$:
\begin{equation}
  \label{noeq:pop_average_Q}
  \p(\yXf = A \| \yH)
% \equiv \pr(x_1+ \dotsb + x_N = N A \| \varEta) 
=  Q(A),
\qquad
A \in \set*{0,\tfrac{1}{N},\tfrac{2}{N},\dotsc,1}.
\end{equation}
For the moment we are not concerned about the specific form of $Q$ and
about how it was assigned: it could, \eg, arise from maximum-entropy
arguments
\citep[\eg:][]{jaynes1957,jaynes1963,good1963,jaynes1967,aczeletal1975,jaynes1979b,vancampenhoutetal1981,sivia1990,fangetal1997,bretthorst2013}
used with data on the population.
\end{enumerate}

\subsection{Formulae}
%\section{\ding{41} {\itshape The mathematical relations} \ding{41}}
%\section*{3.\hspace{\stretch{1}}The mathematical relations\hspace{\stretch{1}}\mbox{}}
%\addcontentsline{toc}{section}{The mathematical relations}
\label{nosec:main_formulae}

The state of knowledge $\yH$ has the following six (not independent) main
consequences for our probability assignments:

\begin{enumerate}%[wide,label=\textbf{\emph{\Roman*}}.]
  \medskip\item\label{noitem:tot_plaus}Probability for the population state:
\begin{equation}
  \label{noeq:joint_plaus_N_homog}
  \p(\yX = \yR \| H) = \binom{N}{N\yRf}^{-1} Q(\yRf).
\end{equation}

\medskip
\item\label{noitem:marginal}Probability for the state $\yx$ of any subpopulation
  of $n$ units:
\begin{equation}
  \label{noeq:marginal}
    \p(\yx = \yr \| \yH) =
\sum_{N A =0}^{N} 
\binom{N-n}{N A-n\yrs}\binom{N}{N A}^{-1}\,
Q(A).
\end{equation}
Note that the only summands contributing to this sum are those for which
$n\yrs \le NA \le N$; the others are zero because by definition
$\tbinom{M}{y}=0$ if $y<0$. This remark applies to all the sums of this
kind in the rest of this Note.

\medskip
\item\label{noitem:conditional}Probability for the subpopulation
  state conditional on a population state:
\begin{equation}
  \label{noeq:conditional_total_state}
  \p(\yx = \yr \| \yX = \yR, \yH)
=
\binom{N-n}{N \yRf-n \yrs}.
\end{equation}

\medskip
\item\label{noitem:marginal_average}Probability for the
  subpopulation average $\yxs$:
\begin{multline}
  \label{noeq:subpop_average}
  \p(\yxs = a  \| \yH) = \binom{n}{n a}
 \sum_{N A=0}^{N}
\binom{N-n}{N A-n a}\binom{N}{N A}^{-1}\,
Q(A),
\\
a \in \set*{0,\tfrac{1}{n},\tfrac{2}{n},\dotsc,1}.
\end{multline}

\medskip
\item\label{noitem:conditional_average}Probability for the subpopulation
  average conditional on the population average:
\begin{equation}
  \label{noeq:conditional_prob}
  \p(\yxs = a \| \yXf = A, \yH)
=
\binom{n}{n a}\binom{N-n}{N A-n a}\binom{N}{N A}^{-1}.
\end{equation}

\medskip
\item\label{noitem:moments}The product of the states of any $m$ distinct
  units from a given subpopulation,
  \begin{equation*}
    x_{i_1} x_{i_2} \dotsm x_{i_m},
    \qquad 1\le i_1 < i_2 < \dotsb < i_m \le n
  \end{equation*}
  has an expectation equal to that of the subpopulation average of such
  products, is independent of the subpopulation size $n$:
\begin{subequations}
\label{noeq:expe_products}
\begin{align}
  \expe{x_{i_1} \dotsm x_{i_m} \| \yH}
&=
\expe{\sav{\underbrace{\yx \dotsm \yx}_{\text{$m$ factors}}} \| \yH}
=
\expe{\av{\underbrace{\yX \dotsm \yX}_{\text{$m$ factors}}} \| \yH},
\\
\intertext{and has an explicit expression in terms of $Q$:}
  \begin{split}
\expe{x_{i_1} \dotsm x_{i_m} \| \yH}
&=
\binom{N}{m}^{-1}
%\frac{(N-m)!}{N!}
\sum_{N A=0}^N %m!\, 
\binom{N A}{m}\, Q(A)
\\
&\equiv
%\frac{(N-m)!}{N!}
\sum_{N A=0}^N %m!\, 
\binom{N-m}{N A-m}
\binom{N}{N A}^{-1} Q(A).
\end{split}
\end{align}
\end{subequations}
\end{enumerate}

\medskip


A useful relation connects the expectation of a
product~\eqref{noeq:expe_products} and the $m$th \emph{factorial moment}
\citep{potts1953} of the probability distributions for the averages. The
$m$th factorial moment of the subpopulation average $\yxs$ is defined by
\begin{equation}
  \label{noeq:fact_mom_defin}
\vphantom{\underbrace{\yxs}_{m}}\expeb*{
\smash{\underbrace{n\yxs\,(n\yxs-1)\dotsm \bigl(n\yxs-(m-1)\bigr)}_{\text{$m$ factors}}}
\| \yH}
\equiv \expeb*{\frac{(n\yxs)!}{(n\yxs-m)!} \| \yH},
\end{equation}
an analogous definition holding for $\yXf$. We have that
\begin{equation}
  \label{noeq:eq_factmom_prod}
\expe{x_{i_1} \dotsm x_{i_m} \| \yH}
=
  \tfrac{(n-m)!}{n!}\expeb*{\frac{(n\yxs)!}{(n\yxs-m)!} \| \yH}
=
  \tfrac{(N-m)!}{N!}\expeb*{\frac{(N\yXf)!}{(N\yXf-m)!} \| \yH}.
\end{equation}


As a consequence of the above relation, the first three moments of the
probability distributions $\p(\yxs=a\|\yH)$ and $\p(\yXf=A\|\yH)$,
are related by
\begin{subequations}\label{noeq:moments}
  \begin{align}
    \expe{\yxs \| \yH} &= \expe{\yXf \| \yH},
    \\[2\jot]
    \begin{split}
    \expe{\yxs^2 \| \yH} &= \expe{\yXf \| \yH}
                                  \frac{N-n}{(N-1)n}
 +{}
\\&\quad\quad \expe{\yXf^2 \| \yH}\frac{N\,(n-1)}{(N-1)n},
\end{split}
    \\[2\jot]
    \begin{split}
    \expe{\yxs^3 \| \yH} &=
                              \expe{\yXf \| \yH}\frac{(N-n)(N-2n)}{(N-1)(N-2)n^2}+{}
                                    \\
                                    &\quad\quad\expe{\yXf^2 \| \yH}
                                    \frac{3N\,(N-n)(n-1)}{(N-1)(N-2)n^2} +{}
                                    \\
                                    &\quad\quad\quad\expe{\yXf^3 \| \yH}
                                    \frac{N^2\,(n-1)(n-2)}{(N-1)(N-2)n^2}.
                                  \end{split}
                                    % \\[2\jot]
                                    % \expe{\yxs^4 \| \varEta} &=
                                    % \!\begin{aligned}[t] &\expe{\yxf
                                    %   \| \varEta}
                                    %   \frac{(N-n)(N^2+N-6Nn+6n^2)}{(N-1)(N-2)(N-3)n^3}+{}
                                    %   \\%[1.5\jot]
                                    %   &\quad\expe{\yxf^2 \| \varEta}
                                    %   \frac{(7N-11n+1)(N-n)(n-1)N}{(N-1)(N-2)(N-3)n^3}+{}
                                    %   \\
                                    %   &\quad\expe{\yxf^3 \| \varEta}
                                    %   \frac{6(n-1)(n-2)(N-n)N^2}{(N-1)(N-2)(N-3)n^3}
                                    %   +{}
                                    %   \\
                                    %   &\quad\expe{\yxf^4 \| \varEta}
                                    %   \frac{(n-1)(n-2)(n-3)N^3}{(N-1)(N-2)(N-3)n^3}.
                                    % \end{aligned}
  \end{align}
\end{subequations}
Relations for higher moments can be obtained recursively from
\eqn~\eqref{noeq:eq_factmom_prod}. In general, this means that the two sets of
first $m$ moments are related by a homogeneous linear transformation,
\begin{equation}
  \label{noeq:lin_transf_moments}
  \expe{\yxs^m \| \yH} = \sum_{l=1}^m M_{ml}(n,N) \expe{\yXf^l \| \yH},
\end{equation}
with a universal, lower-triangular transformation matrix $M_{ml}(n,N)$ that
depends only on $n$, $N$, and the condition of symmetry~\eqref{noeq:homog_math}.

As intuition suggests, we have 
%$\expe{\yxs^m \| \yH} \xrightarrow{n\to N} \expe{\yXf^m \| \yH}$.
\begin{equation}
  \label{noeq:limit_moments}
  \expe{\yxs^m \| \yH} \xrightarrow{n\to N} 
  \expe{\yXf^m \| \yH},
\qquad
  \expe{\yxs^m \| \yH} \xrightarrow{n\to 1} 
  \expe{\yXf \| \yH},
\end{equation}
the latter because ${x_i}^m=x_i$, since states are $\set{0,1}$-valued.

\bigskip

The core of the six mathematical relations above are
\eqns~\eqref{noeq:marginal} and~\eqref{noeq:subpop_average}. The latter
expresses the probability for the subpopulation average as a mixture of
hypergeometric distributions
\cites[\chap~3]{jaynes1994_r2003}[\sect~4.8.3]{ross1976_r2010}[\sect~II.6]{feller1950_r1968},
with parameters $N,N\yXf,n$, weighted by the probabilities
$\p(\yXf = A \|\yH)$ \citep[\cf][\sect~4, esp.\ \eqn~(22)]{kendall1967}.
The connection between this mixture representation and the condition of
symmetry~\eqref{noeq:homog_math} is well-known in the Bayesian literature
\citep{kendall1967,definetti1969b,heathetal1976,diaconis1977,diaconisetal1980,jaynes1986c}.


\section{Examples of inferential use of the formulae}

\subsection{From network to subnetwork}
\label{nosec:pop2sub_examples}


Let us illustrate with an example how the probability distribution for the
subnetwork average $\yxs$, determined by \eqn~\eqref{noeq:subpop_average},
changes with the subnetwork size $n$. Choose a network-average distribution
$\p(\yXf=A\| \yH)$ belonging to the exponential family
\cites[\sect~4.5.3]{bernardoetal1994}[see also][]{fortinietal2000}:
\begin{equation}
  \label{noeq:full_pop_av_example_ME}
  \p(\yXf = A \| \yH) = Q(A) \propto
\binom{N}{N A}\exp[
\yl_2\, N A\,(N A-1)/2 + \yl_1\, N A].
\end{equation}
This is the form obtained from the principle of maximum relative entropy
\citep[\eg:][]{jaynes1957,jaynes1963,good1963,jaynes1967,aczeletal1975,jaynes1979b,vancampenhoutetal1981,sivia1990,fangetal1997,bretthorst2013}
with first and second moments as constraints and the reference distribution
$Q_0$ defined by $Q_0(A) = 2^{-N}\binom{N}{N A}$, corresponding to a
uniform probability distribution for the network state $\yX$.
%file: distr_scaling_from_full_population.nb
\begin{figure}[!b]
\centering
\includegraphics[width=0.95\columnwidth]{scaled_subpop_probs.pdf}%
\caption{Probability distributions $\p(\yxs = a \| \yH)$ for different
  subnetwork sizes $n$, obtained from a network probability
  distribution $\p(\yXf = A \| \yH)$ having the maximum-etropy
  form~\eqref{noeq:full_pop_av_example_ME}.}
\label{noscaling_distr}
\end{figure}
\begin{figure}[!b]
\centering
\includegraphics[width=0.95\columnwidth]{scaling_subpop_moments.pdf}%
\caption{Moments of the probability distributions $\p(\yxs =a \|
  \yH)$ as functions of the subnetwork size $n$.}
\label{noscaling_moments}
\end{figure}

The probability distribution of \eqn~\eqref{noeq:full_pop_av_example_ME} is
plotted in \fig~\ref{noscaling_distr}, together with the resulting
subnetwork-average distributions $\p(\yxs = a \|\yH)$, for the case in
which $N = 1000$ units, $\lambda_1=-2.55$, $\lambda_2=0.005$, and
$n=10, 50, 100, 250$. The distributions become broader as $n$ decreases,
and the minimum of the original distribution disappears; at the same time
the finite-difference 
\[\frac{\p(\yxs=a+1/n\|\yH)-\p(\yxs=a\|\yH)}{1/n}\]
presents a sharp jump at this minimum when $n\approx 100$.

To the eye familiar with maximum-entropy distributions, the
subnetwork-average distributions of \fig~\ref{noscaling_distr} do not look
like maximum-entropy ones with second-moment constraints. In fact,
they are not and \emph{cannot} be:
\begin{equation}
  \label{noeq:maxent_form_sub}
  \p(\yxs =a  \| \yH)
\ne\kappa\binom{n}{n a}\exp[\yk_2\, n a\,(n a-1)/2 + \yk_1\, n a]
%\quad\text{(false)}
\end{equation}
for any $\kappa, \yk_1, \yk_2$, unless $n=2$. This impossibility holds more
generally for any number of constraints $m$ and subnetwork size $n$ such
that $m<n$. The reason is simple: suppose we have assigned a
maximum-entropy distribution with $m$ moment constraints as the
distribution for the network average. If we want the same kind of
distribution for a subnetwork of size $n$, we are free to play with $m+1$
parameters (normalization included), but we must also satisfy the $n+1$
equations corresponding to the marginalization~\eqref{noeq:subpop_average}.
This is generally impossible unless $m \ge n$. (Impossibilities of a
similar kind appear in statistical mechanics, see \eg\
ref.~\citep{maesetal1999}.)
%file: test_ME_same_under_scaling.nb

This fact can be significant for recent works
\citep[\eg,][]{schneidmanetal2006,shlensetal2006,tkaciketal2006,marreetal2009,tkaciketal2009,ganmoretal2011,shimazakietal2012,tkaciketal2013,shimazakietal2015}
in which a maximum-entropy probability distribution with second- or
third-moment constraints is assigned to relatively small subnetworks
($n < 200$) of neurons. If we assume that such subnetwork is part of a
larger network, and assume the condition of symmetry~\eqref{noeq:homog_math},
then the larger network \emph{cannot} be assigned a maximum-entropy
distribution with the same number of constraints. Vice versa, if we assign
such a maximum-entropy distribution to the larger network, then none of its
subnetwork of enough large size $n$ can be assigned a similar
maximum-entropy distribution. See ref.~\citep{rostamietal2016} for a
broader discussion of this fact and of its consequences.

\medskip

The dependence of the first four moments $\expe{\yxs^m \| \yH}$ as a
function of size $n$ is shown in \fig~\ref{noscaling_moments}. The moments
become practically constant when $n \approx 100$ or larger. The
expectations of $m$-tuple products of states
$\expe{x_{i_1}\dotsm x_{i_m} \| \yH}$, proportional to the factorial
moments, are not shown as they do not depend on $n$.


\subsection{From subnetwork to network}
\label{nosec:from_sub_to_full}

We have seen that, given the condition of symmetry~\eqref{noeq:homog_math},
the probability $\p(\yXf = A \|\yH)$ for the network average determines
that of each subnetwork average, $\p(\yxs \|\yH)$, by the
marginalization \eqn~\eqref{noeq:subpop_average}. The reverse is trivially
not true, since \eqn~\eqref{noeq:subpop_average}, as a linear mapping from
$\RR^{N+1}$ to $\RR^{n+1}$, with $N$ larger than $n$, is onto but not into.
Assigning a probability distribution $\p(\yxs = a \|\yH)$ to a
subnetwork average $\yxs$ does not determine a network distribution
$\p(\yXf = A\|\yH)$: it only restricts the set of possible ones; this
set can in principle be determined via linear-programming methods
\citep{hailperin1965,hailperin1984,hailperin1996,hailperin2006,hailperin2011}.
\begin{innote}
  Analogous situations appear in the truth-valued logical calculus: if the
  composite proposition $\varAlpha\limplies \varBeta$ is assigned the
  truth-value \enquote{true}, then assigning $\varAlpha$ the value
  \enquote{true} also determines the value of $\varBeta$, whereas assigning
  $\varBeta$ the value \enquote{true} leaves the value of $\varAlpha$
  undetermined.
\end{innote}
The same linear-programming methods show that any inference from subnetwork
properties to network ones must necessarily start from some assumptions
$\varIota$ that assign a probability distribution
$\p(\yX = \yR \| \varIota)$ for the network states. The approaches to
this task and reformulations of it have become uncountable: they include
exchangeable models, parametric and non-parametric models, hierarchical
models, general linear models, models via sufficiency, maximum-entropy
models, and whatnot
\citep[\eg:][]{jeffreys1931_r1973,jeffreys1939_r2003,jaynes1994_r2003,bernardoetal1994,gelmanetal1995_r2014,ghoshetal1997,kallenberg2005,gregory2005,sivia1996_r2006,ferreiraetal2007,dawid2013,damienetal2013}.
We now show two examples, based on a maximum-entropy approach, that to our
knowledge have not yet been explored in the neuroscientific literature. For
a concrete application see \citep{rostamietal2016b}.



\paragraph{First example: moment constraints for the network.}
\label{nosec:maxent_moments}
Consider a state of knowledge $\yHa$ leading to the following properties:
\begin{enumerate}%[$\yHa$1.]
\item the expectations of the single and pair averages $\yxs$ and
  $\sav{\yx\yx}$ of a particular subnetwork have given values
  \begin{equation}
    \label{noeq:constr_ex1}
    \expe{\yxs \| \yHa} = c_1, \qquad \expe{\sav{x_i x_j}\|\yHa} = c_2;
  \end{equation}
\item the network probability distribution $\p(\yX = \yR \|\yHa)$
  has maximum relative entropy with respect to the uniform one, given the
  constraints above.
\end{enumerate}

\medskip Then the probability distribution for the network conditional on $\yHa$
is completely determined: it satisfies the symmetry
property~\eqref{noeq:homog_math} and is defined by
\begin{multline}
  \label{noeq:pop_distr_maxent1}
  \pf(\yX =\yR \|\yHa) =
\varKappa\exp[\yL_2 N\yRf\,(N\yRf-1)/2 + \yL_1 N\yRf]
\\
\!\begin{aligned}[b]
&\text{with $\varKappa, \yL_m$, such that the distribution is normalized and}
\\
&\varKappa\sum_{N A=0}^N %m!\, 
\binom{N-m}{N A-m}
\exp[\yL_2 N A\,(N A-1)/2 + \yL_1 N A]
= c_m, \quad m=1,2.
\end{aligned}
\end{multline}
We omit the full proof of this statement: it is a standard application of
the maximum-entropy procedure
\citep[\eg:][]{jaynes1957,jaynes1963,good1963,jaynes1967,jaynes1979b,vancampenhoutetal1981,sivia1990,fangetal1997,bretthorst2013},
combined with the equality~\eqref{noeq:expe_products} of subnetwork and
network expectations, \eg
\begin{equation}
  \label{noeq:exploit_eq_expects}
  c_2 = \expe{\sav{\yx\yx}\|\yHa} = 
\binom{N}{2}^{-1}
\sum_{N A=0}^N %m!\, 
\binom{N A}{2} \, \p(\yXf = A\|\yHa),
\end{equation}
and with relations~\eqref{noeq:joint_plaus_N_homog},
\eqref{noeq:conditional_total_state}. This example is easily generalized to
any number $m$ of constraints such that  $m\le n$.

Note again that, as remarked in \sect~\ref{nosec:pop2sub_examples}, the
subnetwork from which the averages in the
expectations~\eqref{noeq:constr_ex1} are calculated has a probability
distribution $\p(\yxs =a \|\yH)$ determined by the
marginalization~\eqref{noeq:subpop_average} and does \emph{not} have a
maximum-entropy form with the same number of constraints.
%file: test_ME_same_under_scaling.nb


\paragraph{Second example: subnetwork-distribution constraint.}
\label{nosec:maxent_fullsubpop}
Consider another state of knowledge $\yHb$ leading to the following
properties:
\begin{enumerate}%[wide,label=$\yHb$\arabic*.]
\item the average $\yxs$ of a particular
  subnetwork has a probability distribution $q$:
  \begin{equation}
    \label{noeq:constr_subpop_distr}
    \p(\yxs =a \|\yHb) = q(a);
  \end{equation}
\item the probability distribution for the network, $\p(\yX = \yR
  \|\yHb)$, has maximum relative entropy with respect to the uniform
  one, given the constraint above.
\end{enumerate}

\medskip Then the probability distribution for the network given $\yHb$ is
completely determined and satisfies the symmetry
property~\eqref{noeq:homog_math}:
\begin{multline}
  \label{noeq:pop_distr_maxent2}
  \p(\yX= \yR \|\yHb) =
\exp\Biggl[
\sum_{n a=0}^n \yL_{ a}
%\binom{N}{N\yXf}^{-1}
\binom{n}{n a}
\binom{N-n}{N\yRf-n a}\Biggr]
\\
\!\begin{aligned}[b]
&\text{with $\yL_{ a}$ such that}
\\
&\sum_{N A=0}^N 
%\binom{N}{N A}^{-1}
\binom{n}{n a}
\binom{N-n}{N A-n a}\,
\exp\Biggl[
\sum_{n a=0}^n \yL_{ a}
%\binom{N}{N A}^{-1}
\binom{n}{n a}
\binom{N-n}{N A-n a}\Biggr]
=q( a)
\end{aligned}
\end{multline}
(the normalization constraint being unnecessary since $q$ is normalized).
This result is just another application of the maximum-entropy procedure
with $n+1$ (linear) constraints given by \eqn~\eqref{noeq:marginal}, where
the left-hand side is now given and equal to $q(a)$.

This example is equivalent to the generalization of the previous one with
$n$ moment constraints, since knowledge of $\p(\yxs=a \| \yHb)$ is
equivalent to knowledge its first $n$ moments.

***



In this note we would like to analyse and warn about a subtle assumption
behind the \me\ method when it is applied to a population. It can informally
be put this way:
\begin{quote}
  \emph{the \me\ method assumes that the population it is applied to is
    completely isolated from any larger population.}
\end{quote}

\mynote{Version 1}
The \me\ method does not construct a probability distribution out of
nothing, but starting from a uniform distribution. A uniform distribution
is an innocuous assumption for a set of non-composite events, like the
outcomes of a die roll, and also for some sets of composite events, like
the outcomes of the roll of two dice. In the latter case multiplicities
appear.

When applied to a subpopulation, the \me\ method assumes that the uniform over
the larger population is uniform, and therefore factorizable. The new
distribution of the subpopulation will not be uniform, but that of the full
population will still be factorizable into the one for the subpopulation and the
rest.

A uniform distribution, however, is not the right one when we suppose that
learning about an event may tell us something about a related event. For
example, consider 1000 tosses of a particular coin and assume a uniform
distribution over the possible $2^{1000}$ outcomes. If we learn that the
first 999 tosses yielded all \enquote{heads}, the probability calculus
tells us that the probability for the 1000th toss is still 50\%/50\%. It
is a consequence of our choice of a uniform distribution: we have
implicitly declared all tosses to be completely independent, completely
\emph{irrelevant} to one another. This fact is well-known in sampling
theory. A more telling example in fact is that of a presidential election
with two candidates: each citizen will vote for one or the other. We do
survey sampling on a large number of citizens to guess the election's
outcome. If we assumed a uniform distribution over the possible
combinations of choices of all citizens, our sampling would be completely
irrelevant for the choices of the rest of the population.




The latter example has many similarities with that of a neuronal binary
population. When we record the neuronal activity of a sample of neurons from a
brain area, we assume that our measurements can tell us something -- no
matter how vague or imprecise -- about the whole brain area. This means
that we are not assuming a uniform distribution over all possible states of
the area.




\mynote{Version 2}
This may come as a surprise. The method simply requires a number of
exhaustive and mutually exclusive events, and if these are composite events
the final distribution may have a multiplicity factor. When we consider the
$2^{N}$ states of $N$ units we are not excluding that these might be
marginals of $2^{M}$ states of $M$ units. Each one has the same
multiplicity $2^{M-N}$, but this constant multiplicity factor disappears
by normalization. So the method applies just as in the case of $N$ units
only, right?

Right, but 

Right, and that is where the problem lies. This way of counting of
multiplicities assumes an underlying 

Wrong. In our reasoning we have made subtle assumptions of independence
between the full population and the subpopulation. The problem is that the
counting of multiplicities is not based on simple enumeration, but already
involves probability considerations. Consider three cases with a full
population of two units, $M=2$, of which we consider one unit, $N=1$.
\begin{itemize}
\item First case: all four states are \emph{possible}. The two states of
  the first unit have multiplicity $2$ each. The usual \me\ distribution
  obtains.
\item Second case: only the states with at most one active unit are
  possible. The state $\yxx_1=1$ of the first unit has multiplicity
  $2$, and $\yxx_1=1$ has multiplicity $1$. The \me\ distribution has
  multiplicity factors.
\item Third case: states with at most one active unit are, say, $10^{9}$
  times more probable than the state with no active units. But all four
  states are \emph{possible}. By enumeration this case is like the first:
  multiplicities $(1,1)$. But by common sense it is more similar to the
  second: multiplicities $(2,1)$ for most practical purposes.
\end{itemize}

This simple example shows that the multiplicity inspection that must
precede a \me\ application already involves probability considerations at
the level of the full population. The usual reasoning by enumeration
implicitly assumes a uniform distribution or at least a \emph{factorizable}
distribution.

***If the distribution is factorizable, however, it means that examination of
the subpopulation \emph{cannot give us any insights about the population it is a
  part of}. This is obviously contrary to the reason why we made neuronal observations.

Consider the following ways of proceeding. We:
\begin{enumerate}
\item have a population with $N$ units, $2^{N}$ possible states
\item expect averages of $\yx$ active neurons and $\yxxs$ active pairs
\item use maximum-entropy to choose a probability distribution for the
  states of the $N$ units conforming to our expectations.
\end{enumerate}

We:
\begin{enumerate}
\item have a population with $M$ units, $2^{M}$ possible states
\item expect that any subpopulation of $N$ units has $\yxs$ active
  neurons and $\yxxs$ active pairs
\item use maximum-entropy to choose a probability distribution for the
  states of the $M$ units conforming to our expectations
\item marginalize to find the probability distribution for the states of
  $N$ units.
\end{enumerate}



  \section{Sketched proofs}
  \label{nosec:derivations}

  Variants of the following derivations and combinatorial considerations
  can be found \eg\ in
  \cites[\chaps~I--IV]{whitworth1867_r1965}[\chap~II]{feller1950_r1968}[\chap~3]{jaynes1994_r2003};
  see also \citep{whitworth1897}.

  To derive the joint probability distribution
  \eqref{noeq:joint_plaus_N_homog} from that for the network
  average~\eqref{noeq:pop_average_Q}, consider that if the network total
  is $N\yXf$, then $N\yXf$ out of $N$ units are active, and there are
  $\tbinom{N}{N\yXf}$ possible states for which this can be true; therefore
  \begin{equation}
    \labelbis{eq:joint_plaus_N_homog}
    \p(\yX = \yR \| H) = \binom{N}{N\yRf}^{-1}Q(\yRf).
  \end{equation}
An analogous reasoning for $n$ and $\yxs$ leads to an analogous equality,
\begin{equation}
  \label{noeq:aver_subpop}
  \p(\yx=\yr \| H) = \binom{n}{n\yrs}^{-1} \p(\yxs=\yrs\|\yH),
\end{equation}
for the subnetwork.

\bigskip 

Let us next consider the probability $\p(\yxs =a \| \yXf = A,\yH)$ for
the subnetwork average $\yxs$ conditional on the network average $\yXf$.
There are $\tbinom{N}{N\yXf}$ possible network states if the network
average is $\yXf$, \ie\ if $N\yXf$ units are in state $1$; the conditional
probability of each is therefore $1/\tbinom{N}{N\yXf}$, owing to the
symmetry assumption~\eqref{noeq:homog_math}. Now consider the subnetwork of the
first $n$ units. The conditional probability of having $n\yxs$ specific
ones in state $1$ is the sum of the probabilities of all states for
which $N\yXf-n\yxs$ of the remaining $N-n$ units are in state $1$; there are
$\tbinom{N-n}{N\yXf-n\yxs}$ such states, all equally probable. Finally,
there are $\tbinom{n}{n\yxs}$ possible ways, all equally probable, in which
$n\yxs$ of the first $n$ units can be in state $1$. In formulae,
\begin{equation}
\label{noeq:conditional_prob_explained}
\begin{split}
      \p(\yxs =a \| \yXf=A, \yH)
      &=
      \sum_{\yr}^{\yrs=a} \sum_{\yR}^{\yRf=A} 
      \p(\yx =\yr \|  \yX = \yR, \yH) \,
      \p(\yX =\yR  \| \yXf=A,\yH),
      \\
      &=
      \sum_{\yr}^{\yrs=a} \sum_{\yR}^{\yRf=A} 
      \p(\yx=\yr \|  \yX =\yR, \yH) \,
      \binom{N}{N A}^{-1},
      \\
      &=\sum_{\yr}^{\yrs=a} 
      \binom{N-n}{N A-n a}\binom{N}{N A}^{-1},
      \\
      &=
      \binom{n}{n a}\binom{N-n}{N A-n a}\binom{N}{N A}^{-1},
\end{split}
\end{equation}
  which is the conditional probability~\eqref{noeq:conditional_prob}. Note
  that this is just a derivation of the hypergeometric distribution
  \cites[\chap~3]{jaynes1994_r2003}[\sect~4.8.3]{ross1976_r2010}[\sect~II.6]{feller1950_r1968},
  which describes the probability of, say, drawing a proportion of $\yxs$
  blue balls in $n$ drawings without replacement from an urn with $N$
  balls, a fraction $\yXf$ of which are blue.

  \bigskip The probability of a subnetwork average $\yxs$ is then, by
  marginalization,
  \begin{equation}
    \label{noeq:subpop_average_explained}
    \begin{split}
      \p(\yxs =a \| \yH)
      &= \sum_{N A=0}^N\p(\yxs = a \| \yXf = A, \yH)\,
      \p(\yXf = A \| \yH),
      \\
      &=\sum_{N A=0}^N
      \binom{n}{n a}\binom{N-n}{N A-n a}\binom{N}{N A}^{-1}
      Q(A).
    \end{split}
  \end{equation}
  which proves the subnetwork-average formula~\eqref{noeq:subpop_average}.
  This formula, combined with \eqns~\eqref{noeq:aver_subpop} and
  \eqref{noeq:joint_plaus_N_homog}, leads to the conditional
  probability~\eqref{noeq:conditional_total_state}.



  \bigskip The independence of the expectation of products of states from
  the subnetwork size is trivial by marginalization:
  \begin{multline}
    \label{noeq:margin_products}
    \sum_{\yx} x_1\dotsm x_m \p(\yx =\yr \| \yH)
      =\sum_{\yr,\yR}  r_1\dotsm r_m \p(\yx=\yr \| \yX=\yR,\yH)
      \, \p(\yX=\yR \| \yH),
      \\
      \begin{aligned}
      &=\sum_{\yr,\yR} r_1\dotsm r_m\,\delt(R_1-r_1)\dotsm\delt(R_m-R_m)
      \p(\yX = \yR \| \yH),
      \\
      &=\sum_{\yR} R_1\dotsm R_m \p(\yX =\yR \| \yH).
    \end{aligned}
  \end{multline}
  All such $m$-fold products have the same expectation by symmetry,
  therefore their subnetwork average will do, too, being an average of
  equal terms.

  Now consider the sum of all distinct products of states of two units in
  the subnetwork:
  \begin{equation*}
    x_1 x_2 + x_1 x_3 + \dotsb + x_{n-1} x_n.
  \end{equation*}
  The terms in this sum are either $0$ or $1$. The non-vanishing ones are
  those with index pairs chosen from the $n\yxs$ units of the subnetwork
  which are in state $1$, and there are $\tbinom{n\yxs}{2}$ such choices,
  so the sum above is equal to $\tbinom{n\yxs}{2}$. The sum has
  $\tbinom{n}{2}$ terms, so their average is
  $\tbinom{n\yxs}{2}/\tbinom{n}{2}$. Generalizing the argument to products
  of $m$ units, we have that
  \begin{equation}
    \sav{x_{i_1} \dotsm x_{i_m}} = \binom{n\yxs}{m} \binom{n}{m}^{-1}.
  \end{equation}
  Then, using \eqn~\eqref{noeq:subpop_average},
  \begin{multline}
    \label{noeq:expect_product_m}
    \expe*{\sav{x_{i_1} \dotsm x_{i_m}} \| \yH}
    \\
    \begin{aligned}[b]
      &=\tfrac{(n-m)!}{n!}
      \expe*{m!\,\tbinom{n\yxs}{m}  \| \yH}
      \\
      &\equiv\frac{(n-m)!}{n!}
      \sum_{n a=0}^n m!\, \binom{n a}{m} \p(\yxs =a \|\yH),
      \\
      &=\frac{(n-m)!}{n!} \sum_{N A=0}^N
      Q( A)
      \Biggl[ 
      \sum_{n a=0}^n 
      m!\,\binom{n a}{m}\, \binom{n}{n a}\binom{N-n}{N A-n a}\binom{N}{N A}^{-1} 
      \Biggr].
    \end{aligned}
  \end{multline}
  The expression in brackets is the $m$th factorial moment of the
  hypergeometric function, and is given by \citep{potts1953}
%file: factorial_moments_etc.nb
  \begin{equation}
    \sum_{n a=0}^n m!\,\binom{n a}{m} \binom{n}{n a}\binom{N-n}{N\yXf-n a}
    \binom{N}{N\yXf}^{-1} 
    =
    m!\,\binom{n}{m} \binom{n a}{m}\binom{N}{m},
  \end{equation}
  which combined with the previous equation yields the second line of
  \eqn~\eqref{noeq:expe_products}; its last equality comes from the identity
  \begin{equation}
    \label{noeq:binom_identity}
    \binom{N}{M}\binom{M}{m}=\binom{N}{m}\binom{N-m}{M-m},
  \end{equation}
  easily derived by writing the binomial coefficients in terms of
  factorials. Finally, \eqns~\eqref{noeq:moments}, relating the moments of
  the distributions for subnetwork and network averages, is obtained
  from the definition of moments,
  \begin{equation}
    \label{noeq:moments_def}
    \expe*{\yxs^m \| \yH} \defd
    \sum_{n a=0}^{n} a^m \p(\yxs = a  \| H),
    \quad
    \expe{\yXf^m \| \yH} \defd
    \sum_{N A=0}^{N} A^m \p(\yXf = A  \| H),
  \end{equation}
  replaced in the equalities for the factorial
  moments~\eqref{noeq:eq_factmom_prod}, by recursively solving in terms of
  the moments of the network distribution.

  *******


  

Here is an example.

Suppose our desired constraints are $\expe{\yxs } = c_1$ and
$\expe{\yxxs} = c_2$, the expectations being given by the fourth term of
\eqn~\eqref{eq:expe_products}. Applying \me\ to the distribution of the
average of the full population we find
\begin{equation}
  \label{eq:full_pop_av_example_ME}
  \p(\yXf = \yRf \| \yHa)  = \yL\,
\binom{N}{N \yRf}\exp\biggl[
\yL_2 \yRf \,\frac{N \yRf-1}{N-1} + \yL_1\, \yRf\biggr]
\end{equation}
with such parameters $\yL$, $\yL_1$, $\yL_2$ as to satisfy normalization
and constraints. We call this state of knowledge $\yHa$. Marginalization by
\eqn~\eqref{eq:marginal} then gives
\begin{equation}
  \label{eq:full_pop_av_example_ME_marg}
  \p(\yxs = \yrs \| \yHa)  = \yL
  \sum_{N\yRf=0}^N
  \binom{n}{n\yrs} \binom{N-n}{N\yRf-n\yrs} \exp\biggl[
\yL_2 \yRf \,\frac{N \yRf-1}{N-1} + \yL_1\, \yRf\biggr].
\end{equation}
Applying \me\ to the distribution of the average of the sample, using the
third term of \eqn~\eqref{eq:expe_products}, we find
\begin{equation}
  \label{eq:sample_av_example_ME}
  \p(\yxs = \yrs \| \yHb)  = \yl\,
  \binom{n}{n\yrs}
  \exp\biggl[\yl_2 \yrs \,\frac{n \yrs-1}{n-1} + \yl_1\, \yrs\biggr]
\end{equation}
with such parameters $\yl$, $\yl_1$, $\yl_2$ as to satisfy the constraints.
We call this state of knowledge $\yHb$.


The resulting distributions $\p(\yxs = \yrs \| \yHa)$,
$\p(\yxs = \yrs \| \yHb)$ are different.
Figure~\ref{fig:diff_maxent_pop_sample} shows one example, for $N=5000$,
$n=100$, $c_1=0.45$, $c_2=0.35$. The two distributions have slightly
different modes and the one obtained from \me\ at the population level is
more peaked. Another example is shown in
\fig~\ref{fig:diff_maxent_pop_sample_realdata}, for $N=5000$, $n=200$,
and neurobiologically more realistic constraints $c_1=0.045$, $c_2=0.0025$
\cite{rostamietal2016}. The discrepancy is maybe not as large as in the
previous example, but the tails of the distributions are still very
different.


**********************************************************



The neurons recorded in these kinds of experiments are usually picked out
according to an unknown process, and from their observation we expect to
learn something about all other neurons in the same brain area. That is,
they are assumed to be a \enquote{representative random sample} of the
neurons in that area. Our discussion hinges on this often just tacitly
understood assumption.

One of the uses of \me\ methods

number. It is large from large
population of neurons [\cite]. The recorded neurons are usually picked out
from a specific brain area according to an unknown process, and from their
observation in relation to stimuli or behavioral task, we strive for
understanding the mechanism behind neuronal coding\mynote{LM still don't
  know what people mean by this, can we find an unambiguous term or
  rephrase?}. That is, they are assumed to be a \enquote{representative
  random sample} of the neurons in that area.\mynote{This assumption says
  that from the sample we can learn about the population. The relation of
  population activity with stimuli or behaviour is a separate problem, so
  \enquote{this is} doesn't really fit...}

Huge amounts of parallel recordings from hundreds of neurons, available
today, are accompanied by the statistical challenges to be employed for
shedding light on the mechanism behind neuronal coding. The principle of
\me\ was proposed as a way to overcome these challenges by constructing a
full description of the neuronal firing patterns. The \me\ method employs
only first and second order statistics of the representative random sample
to construct a \enquote{maximally noncommittal} \cite{jaynes1963}
probability distribution of the firing patterns [\cite]. \mynote{LM:
  \enquote{noncommittal} doesn't mean anything to me to be honest, even if
  Jaynes used that term. I would like to openly say this, backed up by
  references, as done some paragraphs below.\\It seems they have used \me\
  for other purposes too, sometimes unclear ones. And with all kinds of
  constraints. So we shouldn't be too specific here in relation to purpose
  and constraints. I'd rather give references and the readers can form
  their own ideas about its use.}

Using the pairwise \me\ models many studies investigated the questions such
as, which level of interaction\mynote{ambiguous word} (pairwise or higher-order)
between neurons is suffiecient to explain the observed experimental data
[\cite]? Or how collective behavior of neurons can be related to stimuli or
behavioral tasks [\cite]? add more **

Here we show that there is a quandary in applying \me\ to a representative
random sample of neurons to generate a maximally noncommital distribution
for that sample.

The quandary is this. Assume that our sample of neurons is
representative of some population. If we assign a \me\ distribution to the
sample, then we cannot assign a \me\ distribution to the full population.
Vice versa, If we assign a \me\ distribution to the full population, then
we cannot assign a \me\ distribution to the sample. This impossibility
holds at least for \me\ distribution with moment constraints, and even if
the orders of the moments constrained in the sample and in the full
population are different.

In other words, if our sample is a \enquote{random representative} of some
population, then we must choose which has a \enquote{maximally
  noncommittal} distribution: the sample or the population. We can't choose
both. It goes without saying that if one is \enquote{maximally
  noncommittal}, the other must be somehow \enquote{committal}. Which
choice is most meaningful?

In the rest of the paper we will mathematically show the contradiction
above and generate a \me\ distribution for the full population rather than
the sample. We will also present some probability relations relevant to
random sampling. These relations are well-known in survey sampling and in
the pedagogic problem of drawing from an urn without replacement, yet they
are somewhat hard to find explicitly written in the neuroscientific
literature.

 \mynote{Version 1}
The present note has three nested purposes.

The first and more general is to remind our readers that the \me\ method
rests on subtle assumptions that may be contradictory with other
assumptions we want to make on the data under study.

As a concrete example we show -- and this is the second purpose -- that a
sample of a neuronal population cannot be assigned a \enquote{maximally
  noncommittal} \me\ distribution and at the same time be considered a
\enquote{random representative} of the population.

The proof of the example above rests on some probability relations from
classical random sampling. These relations are somewhat hard to find
explicitly stated in the neuroscientific literature; the third, minor
purpose of this note is to state them explicitly.


Let's clarify at once that our discussion pertains to a binary population at
one specific instant or short window in time. It is possible to
similarly discuss multi-state neuron models and population dynamics; but for
simplicity neurons are here assumed to be in a fixed, active \enquote{$1$}
or inactive \enquote{$0$} state; and evolution, change, time correlations,
and similar concepts do not concern us.


Maximum-entropy models are used for a variety of (sometimes not completely
clear) reasons. For our purposes let's say that the \me\ method is assumed
to generate a \enquote{maximally noncommittal} \cite{jaynes1963} probability
distribution. We intend the quoted expression only as an umbrella term,
also because it means very little without further clarifications.

The neurons recorded in these kinds of experiments are usually picked out
according to an unknown process, and from their observation we expect to
learn something about all other neurons in the same brain area. That is,
they are assumed to be a \enquote{representative random sample} of the
neurons in that area. Our discussion hinges on this often just tacitly
understood assumption.


\mynote{Version 2 }
In this note we would like to show that there is a
contradiction in applying \me\ to a \enquote{representative random sample}
of neurons to generate a \enquote{maximally noncommital} distribution for
that sample.
% \\
% \mynote{V2 }In this note we would like to show that there is a clash between the
% \enquote{representative random sample} spirit and the \enquote{maximally
%   noncommital} spirit of \me\ models applied to such a sample of neurons.

The contradiction is this. Assume that our sample of neurons is
representative of some population. If we assign a \me\ distribution to the
sample, then we cannot assign a \me\ distribution to the full population.
Vice versa, If we assign a \me\ distribution to the full population, then
we cannot assign a \me\ distribution to the sample. This impossibility
holds at least for \me\ distribution with moment constraints, and even if
the orders of the moments constrained in the sample and in the full
population are different.

In other words, if our sample is a \enquote{random representative} of some
population, then we must choose which has a \enquote{maximally
  noncommittal} distribution: the sample or the population. We can't choose
both. It goes without saying that if one is \enquote{maximally
  noncommittal}, the other must be somehow \enquote{committal}. Which
choice is most meaningful?

In the rest of the paper we will mathematically show the contradiction
above and generate a \me\ distribution for the full population rather than
the sample. We will also present some probability relations relevant to
random sampling. These relations are well-known in survey sampling and in
the pedagogic problem of drawing from an urn without replacement, yet they
are somewhat hard to find explicitly written in the neuroscientific
literature.
\fi
\end{document}
